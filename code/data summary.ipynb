{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fdebf3c",
   "metadata": {},
   "source": [
    "### training and test data stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "novel-ambassador",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# DESIGNEDDATAPATH = '../designed_data/cad/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "injured-prince",
   "metadata": {},
   "outputs": [],
   "source": [
    "constructs = {}\n",
    "construct_names = [\n",
    "    'sexism',\n",
    "    'hatespeech'\n",
    "    ]\n",
    "perplexity = 10 # 1, 5, 10, 15, 20\n",
    "runs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "imposed-mentor",
   "metadata": {},
   "outputs": [],
   "source": [
    "DESIGNEDDATAPATH = '../data/data/%s/train/paired_cads_flant5.csv' %construct_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "massive-happiness",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install pickle5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "pressed-northern",
   "metadata": {},
   "outputs": [],
   "source": [
    "paired_data = {}\n",
    "\n",
    "for construct in construct_names:\n",
    "    train_data_path = '../../autoCAD/data/data/data/%s/train/paired_cads_mixed.csv' %construct\n",
    "    paired_data[construct] = pd.read_csv(train_data_path, sep = '\\t')\n",
    "    paired_data[construct]['polyjuice_id'] = [str(i)+'p' for i in paired_data[construct]['original_id']]\n",
    "    paired_data[construct]['chatgpt_id'] = [str(i)+'gpt' for i in paired_data[construct]['original_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "residential-essex",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'original_id', 'counterfactual_id', 'original_text',\n",
       "       'counterfactual_text', 'original_label', 'counterfactual_label', 'diff',\n",
       "       'negation_additions', 'negation_deletions', 'affect word_additions',\n",
       "       'affect word_deletions', 'gender word_additions',\n",
       "       'gender word_deletions', 'identity word_additions',\n",
       "       'identity word_deletions', 'hedges_additions', 'hedges_deletions',\n",
       "       'hate words_additions', 'hate words_deletions', 'polyjuice',\n",
       "       'polyjuice_label', 'chatgpt', 'chatgpt_label', 'flant5', 'flant5_label',\n",
       "       'polyjuice_text', 'chatgpt_text', 'flant5_text', 'mixed_cad_text',\n",
       "       'mixed_cad_type', 'mixed_cad_label', 'polyjuice_id', 'chatgpt_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paired_data[construct].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "surprised-medicare",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sexism\n",
      "original_label\n",
      "non-sexist    1610\n",
      "sexist        1244\n",
      "dtype: int64\n",
      "\n",
      "counterfactual_label\n",
      "MAR            596\n",
      "NMAR          1610\n",
      "non-sexist     648\n",
      "dtype: int64\n",
      "\n",
      "polyjuice_label\n",
      "MAR            553\n",
      "NMAR          1610\n",
      "non-sexist     691\n",
      "dtype: int64\n",
      "\n",
      "chatgpt_label\n",
      "MAR              2\n",
      "NMAR          1610\n",
      "non-sexist    1242\n",
      "dtype: int64\n",
      "\n",
      "flant5_label\n",
      "MAR            103\n",
      "NMAR          1610\n",
      "non-sexist    1141\n",
      "dtype: int64\n",
      "---------------------------------------------------------\n",
      "hatespeech\n",
      "original_label\n",
      "hate        6524\n",
      "not hate    5767\n",
      "dtype: int64\n",
      "\n",
      "counterfactual_label\n",
      "hate        5780\n",
      "not hate    6511\n",
      "dtype: int64\n",
      "\n",
      "polyjuice_label\n",
      "MAR         5613\n",
      "hate        3282\n",
      "not hate    3396\n",
      "dtype: int64\n",
      "\n",
      "chatgpt_label\n",
      "MAR          175\n",
      "hate        5686\n",
      "not hate    6430\n",
      "dtype: int64\n",
      "\n",
      "flant5_label\n",
      "MAR         1069\n",
      "hate        5136\n",
      "not hate    6086\n",
      "dtype: int64\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for construct in construct_names:\n",
    "    print(construct)\n",
    "    print(paired_data[construct].groupby('original_label').size())\n",
    "    print()\n",
    "    print(paired_data[construct].groupby('counterfactual_label').size())\n",
    "    print()\n",
    "    print(paired_data[construct].groupby('polyjuice_label').size())\n",
    "    print()\n",
    "    print(paired_data[construct].groupby('chatgpt_label').size())\n",
    "    print()\n",
    "    print(paired_data[construct].groupby('flant5_label').size())\n",
    "    print('---------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "favorite-nation",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_data = {}\n",
    "constructs = ['sexism', 'hatespeech']\n",
    "\n",
    "test_set_data['sexism'] = pd.read_csv('../../autoCAD/results/intermediate/sexism_results (3).csv', sep = '\\t')\n",
    "test_set_data['hatespeech'] = pd.read_csv('../../autoCAD/results/intermediate/hatespeech_results (3).csv',  sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "unique-newton",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset          sexism    \n",
      "hatecheck        non-sexist      136\n",
      "                 sexist          373\n",
      "in_domain        non-sexist      690\n",
      "                 sexist          534\n",
      "out_of_domain    non-sexist     1800\n",
      "                 sexist         1636\n",
      "out_of_domain_2  non-sexist     5856\n",
      "                 sexist          699\n",
      "out_of_domain_3  non-sexist    15146\n",
      "                 sexist         4854\n",
      "dtype: int64\n",
      "\n",
      "dataset          hatespeech\n",
      "hatecheck        hate           2563\n",
      "                 not hate       1165\n",
      "in_domain        hate            471\n",
      "                 not hate        464\n",
      "out_of_domain    hate          14614\n",
      "                 not hate      19162\n",
      "out_of_domain_2  hate           1260\n",
      "                 not hate       1740\n",
      "out_of_domain_3  hate           5256\n",
      "                 not hate      17067\n",
      "out_of_domain_4  hate           1267\n",
      "                 not hate       5738\n",
      "dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for construct in constructs:\n",
    "    print(test_set_data[construct].groupby(['dataset', construct]).size())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "local-cisco",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['in_domain', 'out_of_domain', 'out_of_domain_2', 'out_of_domain_3',\n",
       "       'out_of_domain_4', 'hatecheck'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_data[construct]['dataset'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "flying-indonesian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>dataset</th>\n",
       "      <th>hatecheck</th>\n",
       "      <th>in_domain</th>\n",
       "      <th>out_of_domain</th>\n",
       "      <th>out_of_domain_2</th>\n",
       "      <th>out_of_domain_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sexism</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>non-sexist</th>\n",
       "      <td>136</td>\n",
       "      <td>690</td>\n",
       "      <td>1800</td>\n",
       "      <td>5856</td>\n",
       "      <td>15146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sexist</th>\n",
       "      <td>373</td>\n",
       "      <td>534</td>\n",
       "      <td>1636</td>\n",
       "      <td>699</td>\n",
       "      <td>4854</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dataset     hatecheck  in_domain  out_of_domain  out_of_domain_2  \\\n",
       "sexism                                                             \n",
       "non-sexist        136        690           1800             5856   \n",
       "sexist            373        534           1636              699   \n",
       "\n",
       "dataset     out_of_domain_3  \n",
       "sexism                       \n",
       "non-sexist            15146  \n",
       "sexist                 4854  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_data['sexism'].groupby(['sexism', 'dataset']).size().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "powered-matthew",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>dataset</th>\n",
       "      <th>hatecheck</th>\n",
       "      <th>in_domain</th>\n",
       "      <th>out_of_domain</th>\n",
       "      <th>out_of_domain_2</th>\n",
       "      <th>out_of_domain_3</th>\n",
       "      <th>out_of_domain_4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hatespeech</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hate</th>\n",
       "      <td>2563</td>\n",
       "      <td>471</td>\n",
       "      <td>14614</td>\n",
       "      <td>1260</td>\n",
       "      <td>5256</td>\n",
       "      <td>1267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not hate</th>\n",
       "      <td>1165</td>\n",
       "      <td>464</td>\n",
       "      <td>19162</td>\n",
       "      <td>1740</td>\n",
       "      <td>17067</td>\n",
       "      <td>5738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dataset     hatecheck  in_domain  out_of_domain  out_of_domain_2  \\\n",
       "hatespeech                                                         \n",
       "hate             2563        471          14614             1260   \n",
       "not hate         1165        464          19162             1740   \n",
       "\n",
       "dataset     out_of_domain_3  out_of_domain_4  \n",
       "hatespeech                                    \n",
       "hate                   5256             1267  \n",
       "not hate              17067             5738  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_data['hatespeech'].groupby(['hatespeech', 'dataset']).size().unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ef3db6",
   "metadata": {},
   "source": [
    "### Delete original and counterfactuals in the datasets to respect licenscing agreements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ec1b47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_data = {}\n",
    "constructs = ['sexism', 'hatespeech']\n",
    "\n",
    "test_set_data['sexism'] = pd.read_csv('../results/intermediate/sexism_results.csv', sep = '\\t')\n",
    "test_set_data['hatespeech'] = pd.read_csv('../results/intermediate/hatespeech_results.csv',  sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87141339",
   "metadata": {},
   "outputs": [],
   "source": [
    "for construct in constructs:\n",
    "    test_set_data[construct] = test_set_data[construct].drop('text', axis=1)\n",
    "    test_set_data['sexism'].to_csv('../results/intermediate/sexism_results.csv', sep = '\\t')\n",
    "    test_set_data['hatespeech'].to_csv('../results/intermediate/hatespeech_results.csv',  sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f39fc6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_id',\n",
       " 'chatgpt_labels',\n",
       " 'hatespeech',\n",
       " 'OG_Linear SVM_0_predictions',\n",
       " 'OG_Linear SVM_0_probabilities',\n",
       " 'OG_Linear SVM_1_predictions',\n",
       " 'OG_Linear SVM_1_probabilities',\n",
       " 'OG_Linear SVM_2_predictions',\n",
       " 'OG_Linear SVM_2_probabilities',\n",
       " 'OG_Linear SVM_3_predictions',\n",
       " 'OG_Linear SVM_3_probabilities',\n",
       " 'OG_Linear SVM_4_predictions',\n",
       " 'OG_Linear SVM_4_probabilities',\n",
       " 'OG_transformer_0_predictions',\n",
       " 'OG_transformer_0_probabilities',\n",
       " 'OG_transformer_1_predictions',\n",
       " 'OG_transformer_1_probabilities',\n",
       " 'OG_transformer_2_predictions',\n",
       " 'OG_transformer_2_probabilities',\n",
       " 'OG_transformer_3_predictions',\n",
       " 'OG_transformer_3_probabilities',\n",
       " 'OG_transformer_4_predictions',\n",
       " 'OG_transformer_4_probabilities',\n",
       " 'CAD_Linear SVM_0_predictions',\n",
       " 'CAD_Linear SVM_0_probabilities',\n",
       " 'CAD_Linear SVM_1_predictions',\n",
       " 'CAD_Linear SVM_1_probabilities',\n",
       " 'CAD_Linear SVM_2_predictions',\n",
       " 'CAD_Linear SVM_2_probabilities',\n",
       " 'CAD_Linear SVM_3_predictions',\n",
       " 'CAD_Linear SVM_3_probabilities',\n",
       " 'CAD_Linear SVM_4_predictions',\n",
       " 'CAD_Linear SVM_4_probabilities',\n",
       " 'CAD_transformer_0_predictions',\n",
       " 'CAD_transformer_0_probabilities',\n",
       " 'CAD_transformer_1_predictions',\n",
       " 'CAD_transformer_1_probabilities',\n",
       " 'CAD_transformer_2_predictions',\n",
       " 'CAD_transformer_2_probabilities',\n",
       " 'CAD_transformer_3_predictions',\n",
       " 'CAD_transformer_3_probabilities',\n",
       " 'CAD_transformer_4_predictions',\n",
       " 'CAD_transformer_4_probabilities',\n",
       " 'aCAD_Linear SVM_0_predictions',\n",
       " 'aCAD_Linear SVM_0_probabilities',\n",
       " 'aCAD_Linear SVM_1_predictions',\n",
       " 'aCAD_Linear SVM_1_probabilities',\n",
       " 'aCAD_Linear SVM_2_predictions',\n",
       " 'aCAD_Linear SVM_2_probabilities',\n",
       " 'aCAD_Linear SVM_3_predictions',\n",
       " 'aCAD_Linear SVM_3_probabilities',\n",
       " 'aCAD_Linear SVM_4_predictions',\n",
       " 'aCAD_Linear SVM_4_probabilities',\n",
       " 'aCAD_transformer_0_predictions',\n",
       " 'aCAD_transformer_0_probabilities',\n",
       " 'aCAD_transformer_1_predictions',\n",
       " 'aCAD_transformer_1_probabilities',\n",
       " 'aCAD_transformer_2_predictions',\n",
       " 'aCAD_transformer_2_probabilities',\n",
       " 'aCAD_transformer_3_predictions',\n",
       " 'aCAD_transformer_3_probabilities',\n",
       " 'aCAD_transformer_4_predictions',\n",
       " 'aCAD_transformer_4_probabilities',\n",
       " 'aCAD_GPT_Linear SVM_0_predictions',\n",
       " 'aCAD_GPT_Linear SVM_0_probabilities',\n",
       " 'aCAD_GPT_Linear SVM_1_predictions',\n",
       " 'aCAD_GPT_Linear SVM_1_probabilities',\n",
       " 'aCAD_GPT_Linear SVM_2_predictions',\n",
       " 'aCAD_GPT_Linear SVM_2_probabilities',\n",
       " 'aCAD_GPT_Linear SVM_3_predictions',\n",
       " 'aCAD_GPT_Linear SVM_3_probabilities',\n",
       " 'aCAD_GPT_Linear SVM_4_predictions',\n",
       " 'aCAD_GPT_Linear SVM_4_probabilities',\n",
       " 'aCAD_GPT_transformer_0_predictions',\n",
       " 'aCAD_GPT_transformer_0_probabilities',\n",
       " 'aCAD_GPT_transformer_1_predictions',\n",
       " 'aCAD_GPT_transformer_1_probabilities',\n",
       " 'aCAD_GPT_transformer_2_predictions',\n",
       " 'aCAD_GPT_transformer_2_probabilities',\n",
       " 'aCAD_GPT_transformer_3_predictions',\n",
       " 'aCAD_GPT_transformer_3_probabilities',\n",
       " 'aCAD_GPT_transformer_4_predictions',\n",
       " 'aCAD_GPT_transformer_4_probabilities',\n",
       " 'aCAD_FT_Linear SVM_0_predictions',\n",
       " 'aCAD_FT_Linear SVM_0_probabilities',\n",
       " 'aCAD_FT_Linear SVM_1_predictions',\n",
       " 'aCAD_FT_Linear SVM_1_probabilities',\n",
       " 'aCAD_FT_Linear SVM_2_predictions',\n",
       " 'aCAD_FT_Linear SVM_2_probabilities',\n",
       " 'aCAD_FT_Linear SVM_3_predictions',\n",
       " 'aCAD_FT_Linear SVM_3_probabilities',\n",
       " 'aCAD_FT_Linear SVM_4_predictions',\n",
       " 'aCAD_FT_Linear SVM_4_probabilities',\n",
       " 'aCAD_FT_transformer_0_predictions',\n",
       " 'aCAD_FT_transformer_0_probabilities',\n",
       " 'aCAD_FT_transformer_1_predictions',\n",
       " 'aCAD_FT_transformer_1_probabilities',\n",
       " 'aCAD_FT_transformer_2_predictions',\n",
       " 'aCAD_FT_transformer_2_probabilities',\n",
       " 'aCAD_FT_transformer_3_predictions',\n",
       " 'aCAD_FT_transformer_3_probabilities',\n",
       " 'aCAD_FT_transformer_4_predictions',\n",
       " 'aCAD_FT_transformer_4_probabilities',\n",
       " 'CAD_mixed_Linear SVM_0_predictions',\n",
       " 'CAD_mixed_Linear SVM_0_probabilities',\n",
       " 'CAD_mixed_Linear SVM_1_predictions',\n",
       " 'CAD_mixed_Linear SVM_1_probabilities',\n",
       " 'CAD_mixed_Linear SVM_2_predictions',\n",
       " 'CAD_mixed_Linear SVM_2_probabilities',\n",
       " 'CAD_mixed_Linear SVM_3_predictions',\n",
       " 'CAD_mixed_Linear SVM_3_probabilities',\n",
       " 'CAD_mixed_Linear SVM_4_predictions',\n",
       " 'CAD_mixed_Linear SVM_4_probabilities',\n",
       " 'CAD_mixed_transformer_0_predictions',\n",
       " 'CAD_mixed_transformer_0_probabilities',\n",
       " 'CAD_mixed_transformer_1_predictions',\n",
       " 'CAD_mixed_transformer_1_probabilities',\n",
       " 'CAD_mixed_transformer_2_predictions',\n",
       " 'CAD_mixed_transformer_2_probabilities',\n",
       " 'CAD_mixed_transformer_3_predictions',\n",
       " 'CAD_mixed_transformer_3_probabilities',\n",
       " 'CAD_mixed_transformer_4_predictions',\n",
       " 'CAD_mixed_transformer_4_probabilities',\n",
       " 'dataset']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(test_set_data[construct].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305c1046",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
