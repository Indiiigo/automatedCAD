{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8e968f8-25f7-40b6-ba23-1142af55e581",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install tqdm\n",
    "#!pip install evaluate\n",
    "#!pip install accelerate -U\n",
    "#!pip install  transformers datasets scipy torch\n",
    "#!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e337dc66-4e0e-435f-9680-6ed3dad6f61d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install evaluate\n",
    "import pandas as pd\n",
    "from transformers import TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "import evaluate\n",
    "#from transformers import AutoTokenizer\n",
    "import os\n",
    "import pandas as pd\n",
    "from transformers import TextClassificationPipeline\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import TextClassificationPipeline\n",
    "from transformers import TrainingArguments\n",
    "from transformers import EarlyStoppingCallback, IntervalStrategy\n",
    "from datasets import Dataset\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "from datasets import concatenate_datasets\n",
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "\n",
    "import torch\n",
    "import gc\n",
    "from numba import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "159d363b-512c-4da8-a63a-9750928b382d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## important settings\n",
    "run = 4\n",
    "runs = 1\n",
    "epochs = 5\n",
    "## model used for experiments\n",
    "model_name=\"google/flan-t5-base\"\n",
    "model_max_length = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69910fc7-9635-43b0-918c-c4ed25c0eb4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "\n",
    "# Load tokenizer of FLAN-t5-base\n",
    "#tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd54f17-42cd-489a-ba4c-2c5ea778e26b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf827659-5cc8-442e-9dbf-94208e0a98e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "constructs = ['sexism']\n",
    "construct_names = [\n",
    "    'sexism',\n",
    "    ]\n",
    "perplexity = 10 # 1, 5, 10, 15, 20\n",
    "\n",
    "\n",
    "reverse_label_encode = {'sexism' : {\"1\" : 'sexist', \"0\" : 'non-sexist'},\n",
    "                        'hatespeech' : {\"1\" : 'hate', \"0\" : 'not hate'}\n",
    "                       }\n",
    "            \n",
    "label_encode = {'hatespeech': {'hate' : \"1\", 'not hate': \"0\"},\n",
    "                    'sexism' : {'sexist' : \"1\", 'non-sexist': \"0\"}\n",
    "                   }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae66a636-0e31-4c53-a64a-81a98da630ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "               # ('MNB', MultinomialNB),\n",
    "               #('Linear SVM', LinearSVC),\n",
    "               # ('LR', LogisticRegression),\n",
    "               # ('RF', RandomForestClassifier),\n",
    "               ('transformer', 'transformer')\n",
    "]\n",
    "\n",
    "features = ['_TF-IDF', '_fasttext']\n",
    "\n",
    "modes = {\n",
    "         'OG' : ('original_text', 'original_label'),\n",
    "         'CAD' : ('counterfactual_text', 'counterfactual_label'),\n",
    "         'aCAD' : ('polyjuice', 'polyjuice_label'),\n",
    "         'aCAD_GPT' : ('chatgpt', 'chatgpt_label'),\n",
    "         'aCAD_FT' : ('flant5', 'flant5_label'),\n",
    "         'CAD_mixed' : ('mixed_cad_text', 'mixed_cad_label'),   \n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0dfd9d8-5067-41c8-96a1-2aeb9215134c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "paired_data = {}\n",
    "\n",
    "for construct in construct_names:\n",
    "    train_data_path = '%s' %construct\n",
    "    # paired_data[construct] = pd.read_csv(train_data_path + '/paired_adv_cad_GPT_%d.csv' %(perplexity), sep = '\\t')\n",
    "    paired_data[construct] = pd.read_csv(train_data_path + '/paired_cads_mixed.csv', sep = '\\t')\n",
    "    \n",
    "    paired_data[construct]['polyjuice_id'] = [str(i)+'p' for i in paired_data[construct]['original_id']]\n",
    "    paired_data[construct]['chatgpt_id'] = [str(i)+'gpt' for i in paired_data[construct]['original_id']]\n",
    "    paired_data[construct]['flant5_id'] = [str(i)+'ft' for i in paired_data[construct]['original_id']]\n",
    "    paired_data[construct]['mixed_id'] = [str(i)+'m' for i in paired_data[construct]['original_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c928903c-345a-472c-9ddb-542923c5ce69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sexism\n",
      "original_label\n",
      "non-sexist    1610\n",
      "sexist        1244\n",
      "dtype: int64\n",
      "\n",
      "counterfactual_label\n",
      "MAR            596\n",
      "NMAR          1610\n",
      "non-sexist     648\n",
      "dtype: int64\n",
      "\n",
      "polyjuice_label\n",
      "MAR            553\n",
      "NMAR          1610\n",
      "non-sexist     691\n",
      "dtype: int64\n",
      "\n",
      "chatgpt_label\n",
      "NMAR          1610\n",
      "non-sexist    1244\n",
      "dtype: int64\n",
      "\n",
      "flant5_label\n",
      "MAR            103\n",
      "NMAR          1610\n",
      "non-sexist    1141\n",
      "dtype: int64\n",
      "\n",
      "mixed_cad_label\n",
      "MAR            375\n",
      "NMAR          1610\n",
      "non-sexist     869\n",
      "dtype: int64\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "## print loaded data\n",
    "\n",
    "for construct in construct_names:\n",
    "    print(construct)\n",
    "    print(paired_data[construct].groupby('original_label').size())\n",
    "    print()\n",
    "    print(paired_data[construct].groupby('counterfactual_label').size())\n",
    "    print()\n",
    "    print(paired_data[construct].groupby('polyjuice_label').size())\n",
    "    print()\n",
    "    print(paired_data[construct].groupby('chatgpt_label').size())\n",
    "    print()\n",
    "    print(paired_data[construct].groupby('flant5_label').size())\n",
    "    print()\n",
    "    print(paired_data[construct].groupby('mixed_cad_label').size())\n",
    "    print('---------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87a8ac64-598a-4f3f-9f23-47daa7baec1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_reverse = {'hate' : 'not hate', 'not hate' : 'hate', 'MAR' : 'MAR',\n",
    "                 'sexist' : 'non-sexist', 'non-sexist' : 'sexist'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c3ffdad-8612-4ddb-9f47-f0092d4d75ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize\n",
    "#nltk.download(\"punkt\")\n",
    "\n",
    "# Metric\n",
    "metric = evaluate.combine([\"accuracy\", \"f1\", \"precision\", \"recall\"])\n",
    "\n",
    "# helper function to postprocess text\n",
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [label.strip() for label in labels]\n",
    "\n",
    "    # rougeLSum expects newline after each sentence\n",
    "    preds = [\"\\n\".join(sent_tokenize(pred)) for pred in preds]\n",
    "    labels = [\"\\n\".join(sent_tokenize(label)) for label in labels]\n",
    "    \n",
    "    ## non-expected outputs are mapped to 0 \n",
    "    preds = [\"0\" if ((x != \"0\") and (x != \"1\")) else x for x in preds]\n",
    "    \n",
    "    #print(preds)\n",
    "    #print(labels)\n",
    "    return preds, labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec4b9e8b-6444-4841-b794-ae22b06d1f37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "n = random.randint(0,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d53252e-e82f-4c08-bdc7-18d4b392a913",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import set_seed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5834b984-8055-4532-b9a7-fcbd798fbb0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "## main optimization function\n",
    "def train_model(data_, construct = 'hatespeech',\n",
    "                features = 'TF-IDF', classifier_type = None,\n",
    "                mode = 'OG', run = 0):\n",
    "    \n",
    "    ## reset\n",
    "    #trainer = None\n",
    "    #results = None\n",
    "    #tokenizer = None\n",
    "    #metric = None\n",
    "    #from transformers import set_seed\n",
    "\n",
    "    set_seed(run)\n",
    "    \n",
    "    ## new metrics and tokenizer are initialized for each hyperparameter run\n",
    "    metric = evaluate.combine([\"accuracy\", \"f1\", \"precision\", \"recall\"])\n",
    "    \n",
    "    \n",
    "    def compute_metrics(eval_preds):\n",
    "        preds, labels = eval_preds\n",
    "        if isinstance(preds, tuple):\n",
    "            preds = preds[0]\n",
    "        decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "        # Replace -100 in the labels as we can't decode them.\n",
    "        labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "        decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "        # Some simple post-processing\n",
    "        decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "        result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "        result = {k: round(v * 100, 4) for k, v in result.items()}\n",
    "        prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "        result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "        return result\n",
    "    \n",
    "    def preprocess_function(sample, padding=\"max_length\"):\n",
    "        max_target_length=3\n",
    "        max_source_length = 512\n",
    "        #print(sample[\"label\"])\n",
    "\n",
    "        # add prefix to the input for t5\n",
    "        inputs = [item for item in sample[\"text\"]]\n",
    "\n",
    "        # tokenize inputs\n",
    "        model_inputs = tokenizer(inputs, max_length=max_source_length, padding=padding, truncation=True)\n",
    "\n",
    "        # Tokenize targets with the `text_target` keyword argument\n",
    "        labels = tokenizer(text_target=sample[\"label\"], max_length=max_target_length, padding=padding, truncation=True)\n",
    "\n",
    "        # If we are padding here, replace all tokenizer.pad_token_id in the labels by -100 when we want to ignore\n",
    "        # padding in the loss.\n",
    "        if padding == \"max_length\":\n",
    "            labels[\"input_ids\"] = [\n",
    "                [(l if l != tokenizer.pad_token_id else -100) for l in label] for label in labels[\"input_ids\"]\n",
    "            ]\n",
    "\n",
    "        model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "        return model_inputs\n",
    "    \n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    \n",
    "    data = data_.copy()\n",
    "    # step 1. stratify and equalize classes (by original labels)\n",
    "    g = data.groupby(modes['OG'][1])\n",
    "    training_data = g.apply(lambda x: x.sample(g.size().min()).reset_index(drop=True))\n",
    "    training_data = training_data.sample(frac=1)\n",
    "    #print(len(training_data))\n",
    "    #print(training_data.head()[\"original_text\"])\n",
    "    \n",
    "    ## DIFFERENT SETTINGS FOR DATA\n",
    "    if mode == 'OG':\n",
    "        training_X = training_data[modes['OG'][0] + features].values\n",
    "        training_y = training_data[modes['OG'][1]].values\n",
    "        \n",
    "        training_data_datamap = [training_data[modes['OG'][0].split('_')[0] + '_id'].values,\n",
    "                                 training_data[modes['OG'][0]].values,\n",
    "                                 training_data[modes['OG'][1]].values,\n",
    "                                 ['original'] * len(training_data[modes['OG'][1]])\n",
    "                                ]\n",
    "    else:\n",
    "        # step 2. keep pos class as is\n",
    "        pos_data = training_data[training_data[modes['OG'][1]] == reverse_label_encode[construct][\"1\"]]\n",
    "        training_X = list(pos_data[modes['OG'][0] + features].values) #adding the OGs\n",
    "        training_y = list(pos_data[modes['OG'][1]].values)\n",
    "            \n",
    "        # Step 3: drop half of the negative data (non-sexist, non-hate)\n",
    "        neg_data = training_data[training_data[modes['OG'][1]] == reverse_label_encode[construct][\"0\"]]\n",
    "        neg_sample_len = len(neg_data)\n",
    "        neg_data = neg_data.sample(n = neg_sample_len//2)\n",
    "        training_X.extend(list(neg_data[modes['OG'][0] + features].values)) #adding the OGs\n",
    "        training_y.extend(list(neg_data[modes['OG'][1]].values))\n",
    "            \n",
    "        # replace with that much counterfactual\n",
    "        neg_cad_data = pos_data#.sample(n = neg_sample_len//2)\n",
    "        # drop the missing CADs (MAR)\n",
    "        neg_cad_data = neg_cad_data[neg_cad_data[modes[mode][1]] != 'MAR']\n",
    "        neg_cad_data = neg_cad_data.sample(n = neg_sample_len//2)\n",
    "        training_X.extend(list(neg_cad_data[modes[mode][0] + features].values)) #adding the CADs\n",
    "        training_y.extend(list(neg_cad_data[modes[mode][1]].values))\n",
    "            \n",
    "        ids = list(pos_data[modes['OG'][0].split('_')[0] + '_id'].values)\n",
    "        ids.extend(list(neg_data[modes['OG'][0].split('_')[0] + '_id'].values))\n",
    "        ids.extend(list(neg_cad_data[modes[mode][0].split('_')[0] + '_id'].values))\n",
    "        \n",
    "        texts = list(pos_data[modes['OG'][0]].values)\n",
    "        texts.extend(list(neg_data[modes['OG'][0]].values))\n",
    "        texts.extend(list(neg_cad_data[modes[mode][0]].values))\n",
    "        \n",
    "        labels = list(pos_data[modes['OG'][1]].values)\n",
    "        labels.extend(list(neg_data[modes['OG'][1]].values))\n",
    "        labels.extend(list(neg_cad_data[modes[mode][1]].values))\n",
    "        \n",
    "        mode_lists = ['original'] * (len(pos_data) + len(neg_data))\n",
    "        mode_lists.extend([modes[mode][1].split('_')[0]] * len(neg_cad_data))\n",
    "        \n",
    "        training_data_datamap = [ids, texts, labels, mode_lists]\n",
    "        \n",
    "    training_data_datamap_df = pd.DataFrame(training_data_datamap).T\n",
    "    training_data_datamap_df.columns = ['id', 'text', 'label', 'data_type']\n",
    "    print('FINAL DIST: ', training_data_datamap_df.groupby('label').size())\n",
    "    \n",
    "    \n",
    "\n",
    "    train_data = []\n",
    "    \n",
    "    for n, text in enumerate(training_X):\n",
    "        train_data.append((text, label_encode[construct][training_y[n]]))\n",
    "    train_df = pd.DataFrame(train_data)\n",
    "    train_df.columns = [\"text\", \"labels\"]\n",
    "    train_df[\"label\"] = train_df[\"labels\"]\n",
    "    dataset = Dataset.from_pandas(train_df)\n",
    "    \n",
    "    #print(train_df.tail())\n",
    "\n",
    "    tokenized_datasets = dataset.map(preprocess_function, batched=True)\n",
    "    #print(f\"Keys of tokenized dataset: {list(tokenized_dataset['train'].features)}\")\n",
    "    #tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "    tokenized_datasets = tokenized_datasets.class_encode_column(\"label\")\n",
    "\n",
    "    ## create splits\n",
    "    split = tokenized_datasets.train_test_split(test_size = 0.2, stratify_by_column=\"label\")\n",
    "    \n",
    "    \n",
    "    split[\"train\"]=split[\"train\"].remove_columns(\"label\")\n",
    "    split[\"train\"]=split[\"train\"].remove_columns(\"text\")\n",
    "    split[\"test\"]=split[\"test\"].remove_columns(\"label\")\n",
    "    split[\"test\"]=split[\"test\"].remove_columns(\"text\")\n",
    "    #print(split[\"train\"][\"input_ids\"][0])\n",
    "    \n",
    "    ## init model\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "    # we want to ignore tokenizer pad token in the loss\n",
    "    label_pad_token_id = -100\n",
    "    \n",
    "    # Data collator\n",
    "    data_collator = DataCollatorForSeq2Seq(\n",
    "        tokenizer,\n",
    "        model=model,\n",
    "        label_pad_token_id=label_pad_token_id,\n",
    "        pad_to_multiple_of=8\n",
    "    )\n",
    "   \n",
    "    ## setup training arguments\n",
    "    training_args = Seq2SeqTrainingArguments(\n",
    "        output_dir='_outflant5/_out_'+str(construct)+\"_\"+str(mode)+\"_\"+str(run),\n",
    "        #evaluation_strategy=\"epoch\",\n",
    "        learning_rate=5e-4,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=16,\n",
    "        \n",
    "        evaluation_strategy=\"no\",\n",
    "        save_strategy=\"epoch\",\n",
    "        save_total_limit=2,\n",
    "        num_train_epochs=epochs,\n",
    "        load_best_model_at_end=False,\n",
    "        weight_decay=0.001,\n",
    "        #save_strategy=\"epoch\",\n",
    "        #do_predict=True,\n",
    "        logging_steps=200,\n",
    "        logging_dir=\"logs\",\n",
    "        skip_memory_metrics=True,\n",
    "        report_to=\"none\",\n",
    "        predict_with_generate=True,\n",
    "        seed=run\n",
    "\n",
    "    )\n",
    "    \n",
    "    \n",
    "    ## setup trainer\n",
    "    trainer =  Seq2SeqTrainer(\n",
    "        args=training_args,\n",
    "        train_dataset=split[\"train\"],\n",
    "        eval_dataset=split[\"test\"],\n",
    "        compute_metrics=compute_metrics,\n",
    "        model=model,\n",
    "        data_collator=data_collator\n",
    "    )\n",
    "    \n",
    "    \n",
    "    trainer.train()\n",
    "    print(str(construct)+\"_\"+str(mode)+\"_\"+str(run))\n",
    "    print(trainer.evaluate())\n",
    "\n",
    "    trainer.save_model(\"_models/flant5_\"+str(construct)+\"_\"+str(mode)+\"_\"+str(run))\n",
    "    \n",
    "    del training_args\n",
    "    \n",
    "    del model\n",
    "    #gc.collect()\n",
    "    del tokenizer\n",
    "    #gc.collect()\n",
    "    del data_collator\n",
    "    #gc.collect()\n",
    "    del trainer\n",
    "    #gc.collect()\n",
    "    del split\n",
    "    gc.collect()\n",
    "    #data_collator = None\n",
    "    #model = None\n",
    "    #trainer = None\n",
    "    #results = None \n",
    "    #tokenizer = None\n",
    "    #metric = None\n",
    "    #split= None\n",
    "    \n",
    "   # gc.collect()\n",
    "    with torch.no_grad():\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    return \"_models/flant5_\"+str(construct)+\"_\"+str(mode)+\"_\"+str(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c110ccd8-2369-4fb5-994e-896865b7daa8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = None\n",
    "trainer = None\n",
    "results = None \n",
    "tokenizer = None\n",
    "metric = None\n",
    "split= None\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed1b11a0-968a-4bd6-a69a-e5299e1417e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#gc.get_objects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba3ae40-e46f-4d8e-ab56-b830f1ebc1b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0fee50c2-63ed-4ce6-8128-7ba1495e328f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OG\n",
      "FINAL DIST:  label\n",
      "non-sexist    1244\n",
      "sexist        1244\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "657fd8936b5a4900b0f411725f5222a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2488 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "457b1f183d194eb0b3bc76c5afe1a19f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/2488 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 11:21, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.228700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.064800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.014600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sexism_OG_4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.42018672823905945, 'eval_accuracy': 85.9438, 'eval_f1': 86.9403, 'eval_precision': 81.1847, 'eval_recall': 93.5743, 'eval_gen_len': 2.423694779116466, 'eval_runtime': 21.9063, 'eval_samples_per_second': 22.733, 'eval_steps_per_second': 1.461, 'epoch': 5.0}\n",
      "CAD\n",
      "FINAL DIST:  label\n",
      "non-sexist    1244\n",
      "sexist        1244\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51b63dac7d724a63aa860538f75faac3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2488 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0dae2d4d62241f286a39883105e6c42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/2488 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 11:20, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.216000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.063700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.021400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sexism_CAD_4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3586411774158478, 'eval_accuracy': 86.747, 'eval_f1': 87.1595, 'eval_precision': 84.5283, 'eval_recall': 89.9598, 'eval_gen_len': 2.467871485943775, 'eval_runtime': 21.9498, 'eval_samples_per_second': 22.688, 'eval_steps_per_second': 1.458, 'epoch': 5.0}\n",
      "aCAD\n",
      "FINAL DIST:  label\n",
      "non-sexist    1244\n",
      "sexist        1244\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a85081bf323b4617bf50232466996211",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2488 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d3b5ffe8b5a45fb9d18a9d76d12c8ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/2488 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 11:21, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.320800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.216300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.158300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sexism_aCAD_4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4675939381122589, 'eval_accuracy': 57.2289, 'eval_f1': 60.9174, 'eval_precision': 56.0811, 'eval_recall': 66.6667, 'eval_gen_len': 2.4056224899598395, 'eval_runtime': 21.9036, 'eval_samples_per_second': 22.736, 'eval_steps_per_second': 1.461, 'epoch': 5.0}\n",
      "aCAD_GPT\n",
      "FINAL DIST:  label\n",
      "non-sexist    1244\n",
      "sexist        1244\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98c137769c09473ca50dba23d6eaef42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2488 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12b53f85b4a24372942b6864803a3038",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/2488 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 11:20, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.219400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.063700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.015500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sexism_aCAD_GPT_4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.39413052797317505, 'eval_accuracy': 84.739, 'eval_f1': 85.214, 'eval_precision': 82.6415, 'eval_recall': 87.9518, 'eval_gen_len': 2.467871485943775, 'eval_runtime': 21.9379, 'eval_samples_per_second': 22.7, 'eval_steps_per_second': 1.459, 'epoch': 5.0}\n",
      "aCAD_FT\n",
      "FINAL DIST:  label\n",
      "non-sexist    1244\n",
      "sexist        1244\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "076aa0b583d44ab68d1aea94e5c5ad7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2488 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a3089a2570a42e4adc5ed58800c0fe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/2488 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 11:20, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.323200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.217100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.149900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sexism_aCAD_FT_4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5219763517379761, 'eval_accuracy': 59.2369, 'eval_f1': 61.7702, 'eval_precision': 58.156, 'eval_recall': 65.8635, 'eval_gen_len': 2.433734939759036, 'eval_runtime': 21.958, 'eval_samples_per_second': 22.68, 'eval_steps_per_second': 1.457, 'epoch': 5.0}\n",
      "CAD_mixed\n",
      "FINAL DIST:  label\n",
      "non-sexist    1244\n",
      "sexist        1244\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46b510526a164d6e81aa03c58e5c364f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2488 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "432b1aaa5fd14b3fac04530104b58c37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/2488 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 11:20, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.270500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.155600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.100600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sexism_CAD_mixed_4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.42411237955093384, 'eval_accuracy': 73.2932, 'eval_f1': 74.9529, 'eval_precision': 70.5674, 'eval_recall': 79.9197, 'eval_gen_len': 2.433734939759036, 'eval_runtime': 21.9485, 'eval_samples_per_second': 22.689, 'eval_steps_per_second': 1.458, 'epoch': 5.0}\n"
     ]
    }
   ],
   "source": [
    "all_models = []\n",
    "## iterate over constructs\n",
    "for construct in constructs:\n",
    "    model = {}\n",
    "    model['construct'] = construct\n",
    "    ## oterate over modes\n",
    "    for mode in modes:\n",
    "        print(mode)\n",
    "        model['mode'] = mode\n",
    "        \n",
    "        ## iterate over classifier\n",
    "        for classifier_name, classifier_type in classifiers:\n",
    "            model['classifier_name'] = classifier_name\n",
    "            ## iterate over number of runs\n",
    "            #for run in range(runs):\n",
    "            model['run'] = run\n",
    "            if classifier_type == 'transformer':\n",
    "                    model['feature'] = ''\n",
    "                \n",
    "            model['classifier'] = train_model(paired_data[construct], construct,\n",
    "                                                features = model['feature'], classifier_type = classifier_type,\n",
    "                                                mode = mode, run = run)\n",
    "            #device = cuda.get_current_device()\n",
    "            #device.reset()\n",
    "            all_models.append(model.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0993cca-0d3c-4195-abc9-55785d32276d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_sets = ['in_domain', 'out_of_domain', \n",
    "             'out_of_domain_2', 'out_of_domain_3', \n",
    "             #'out_of_domain_4', \n",
    "             'hatecheck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "610803e8-4e23-4601-8384-d66aef2b9329",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_set_data = {}\n",
    "\n",
    "for construct in construct_names:\n",
    "    test_set_data[construct] = {}\n",
    "    for test_set in test_sets:\n",
    "        test_path = '%s/test/%s.csv' %(construct, test_set)\n",
    "        test_set_data[construct][test_set] = pd.read_csv(test_path, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08049c3b-56b1-4757-9928-aebd9b8242e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, precision_recall_fscore_support, roc_curve, roc_auc_score, f1_score, accuracy_score, recall_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96c4134e-2890-4bc6-a235-edc13c333b14",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'construct': 'sexism',\n",
       "  'mode': 'OG',\n",
       "  'classifier_name': 'transformer',\n",
       "  'run': 4,\n",
       "  'feature': '',\n",
       "  'classifier': '_models/flant5_sexism_OG_4'},\n",
       " {'construct': 'sexism',\n",
       "  'mode': 'CAD',\n",
       "  'classifier_name': 'transformer',\n",
       "  'run': 4,\n",
       "  'feature': '',\n",
       "  'classifier': '_models/flant5_sexism_CAD_4'},\n",
       " {'construct': 'sexism',\n",
       "  'mode': 'aCAD',\n",
       "  'classifier_name': 'transformer',\n",
       "  'run': 4,\n",
       "  'feature': '',\n",
       "  'classifier': '_models/flant5_sexism_aCAD_4'},\n",
       " {'construct': 'sexism',\n",
       "  'mode': 'aCAD_GPT',\n",
       "  'classifier_name': 'transformer',\n",
       "  'run': 4,\n",
       "  'feature': '',\n",
       "  'classifier': '_models/flant5_sexism_aCAD_GPT_4'},\n",
       " {'construct': 'sexism',\n",
       "  'mode': 'aCAD_FT',\n",
       "  'classifier_name': 'transformer',\n",
       "  'run': 4,\n",
       "  'feature': '',\n",
       "  'classifier': '_models/flant5_sexism_aCAD_FT_4'},\n",
       " {'construct': 'sexism',\n",
       "  'mode': 'CAD_mixed',\n",
       "  'classifier_name': 'transformer',\n",
       "  'run': 4,\n",
       "  'feature': '',\n",
       "  'classifier': '_models/flant5_sexism_CAD_mixed_4'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "beca399d-e61f-4bf3-9215-119cb133850b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_models/flant5_sexism_OG_4\n",
      "in_domain\n",
      "macro F1: 0.8397730278185185\n",
      "-------------------\n",
      "_models/flant5_sexism_OG_4\n",
      "out_of_domain\n",
      "macro F1: 0.6073546991204692\n",
      "-------------------\n",
      "_models/flant5_sexism_OG_4\n",
      "out_of_domain_2\n",
      "macro F1: 0.6028796745521211\n",
      "-------------------\n",
      "_models/flant5_sexism_OG_4\n",
      "out_of_domain_3\n",
      "macro F1: 0.5881112600983974\n",
      "-------------------\n",
      "_models/flant5_sexism_OG_4\n",
      "hatecheck\n",
      "macro F1: 0.5552959343316334\n",
      "-------------------\n",
      "_models/flant5_sexism_CAD_4\n",
      "in_domain\n",
      "macro F1: 0.8186230926348672\n",
      "-------------------\n",
      "_models/flant5_sexism_CAD_4\n",
      "out_of_domain\n",
      "macro F1: 0.6387335414965596\n",
      "-------------------\n",
      "_models/flant5_sexism_CAD_4\n",
      "out_of_domain_2\n",
      "macro F1: 0.6091739219292868\n",
      "-------------------\n",
      "_models/flant5_sexism_CAD_4\n",
      "out_of_domain_3\n",
      "macro F1: 0.6025049157358632\n",
      "-------------------\n",
      "_models/flant5_sexism_CAD_4\n",
      "hatecheck\n",
      "macro F1: 0.5763764404609475\n",
      "-------------------\n",
      "_models/flant5_sexism_aCAD_4\n",
      "in_domain\n",
      "macro F1: 0.7818916841665708\n",
      "-------------------\n",
      "_models/flant5_sexism_aCAD_4\n",
      "out_of_domain\n",
      "macro F1: 0.5752283548026802\n",
      "-------------------\n",
      "_models/flant5_sexism_aCAD_4\n",
      "out_of_domain_2\n",
      "macro F1: 0.6112313460599061\n",
      "-------------------\n",
      "_models/flant5_sexism_aCAD_4\n",
      "out_of_domain_3\n",
      "macro F1: 0.601992563790233\n",
      "-------------------\n",
      "_models/flant5_sexism_aCAD_4\n",
      "hatecheck\n",
      "macro F1: 0.356126218414354\n",
      "-------------------\n",
      "_models/flant5_sexism_aCAD_GPT_4\n",
      "in_domain\n",
      "macro F1: 0.8078987000237088\n",
      "-------------------\n",
      "_models/flant5_sexism_aCAD_GPT_4\n",
      "out_of_domain\n",
      "macro F1: 0.6291670870219057\n",
      "-------------------\n",
      "_models/flant5_sexism_aCAD_GPT_4\n",
      "out_of_domain_2\n",
      "macro F1: 0.6256657460390929\n",
      "-------------------\n",
      "_models/flant5_sexism_aCAD_GPT_4\n",
      "out_of_domain_3\n",
      "macro F1: 0.6150552792059023\n",
      "-------------------\n",
      "_models/flant5_sexism_aCAD_GPT_4\n",
      "hatecheck\n",
      "macro F1: 0.5874709937209937\n",
      "-------------------\n",
      "_models/flant5_sexism_aCAD_FT_4\n",
      "in_domain\n",
      "macro F1: 0.8098803851016241\n",
      "-------------------\n",
      "_models/flant5_sexism_aCAD_FT_4\n",
      "out_of_domain\n",
      "macro F1: 0.6114880144730892\n",
      "-------------------\n",
      "_models/flant5_sexism_aCAD_FT_4\n",
      "out_of_domain_2\n",
      "macro F1: 0.607798120819566\n",
      "-------------------\n",
      "_models/flant5_sexism_aCAD_FT_4\n",
      "out_of_domain_3\n",
      "macro F1: 0.588840939166315\n",
      "-------------------\n",
      "_models/flant5_sexism_aCAD_FT_4\n",
      "hatecheck\n",
      "macro F1: 0.5588202550971723\n",
      "-------------------\n",
      "_models/flant5_sexism_CAD_mixed_4\n",
      "in_domain\n",
      "macro F1: 0.8144234461984418\n",
      "-------------------\n",
      "_models/flant5_sexism_CAD_mixed_4\n",
      "out_of_domain\n",
      "macro F1: 0.6381155153668252\n",
      "-------------------\n",
      "_models/flant5_sexism_CAD_mixed_4\n",
      "out_of_domain_2\n",
      "macro F1: 0.6475824139422879\n",
      "-------------------\n",
      "_models/flant5_sexism_CAD_mixed_4\n",
      "out_of_domain_3\n",
      "macro F1: 0.6183546559178771\n",
      "-------------------\n",
      "_models/flant5_sexism_CAD_mixed_4\n",
      "hatecheck\n",
      "macro F1: 0.6147983908442757\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "all_results = []\n",
    "\n",
    "for model in all_models:\n",
    "    result = model.copy()\n",
    "    for test_set in test_sets:\n",
    "        result['test_set'] = test_set\n",
    "        test_data = test_set_data[model['construct']][test_set]\n",
    "        construct = model['construct']\n",
    "        \n",
    "        if model['classifier_name'] == 'transformer':\n",
    "            test_features = list(test_data['text'].values)\n",
    "            \n",
    "            tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "            classifier = AutoModelForSeq2SeqLM.from_pretrained(model['classifier'])\n",
    "            classifier.to('cuda')\n",
    "\n",
    "            preds = []\n",
    "            for x in test_features:\n",
    "                inputs = tokenizer.encode_plus(x, padding='max_length', max_length=512, return_tensors='pt').to('cuda')\n",
    "                outputs = classifier.generate(inputs['input_ids'], attention_mask=inputs['attention_mask'], max_length=3, num_beams=1,do_sample=False)\n",
    "                out = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "                preds.append(out)\n",
    "            \n",
    "            \n",
    "            preds,k = postprocess_text(preds,\"\")\n",
    "    \n",
    "            \n",
    "            true = [label_encode[construct][x] for x in test_set_data[construct][test_set][construct].values]\n",
    "       \n",
    "      \n",
    "        else:\n",
    "            print(\"wrong way\")\n",
    "\n",
    "        \n",
    "        scores = precision_recall_fscore_support(true, preds)\n",
    "        test_data['%s_%s_%d_predictions' %(model['mode'], model['classifier_name'],\n",
    "                                              model['run'])] = preds\n",
    "\n",
    "        \n",
    "        result['predictions'] = preds\n",
    "        result['pos_precision'] = scores[0][0]\n",
    "        result['neg_precision'] = scores[0][1]\n",
    "        result['pos_recall'] = scores[1][0]\n",
    "        result['neg_recall'] = scores[1][0]\n",
    "        result['pos_f1'] = scores[2][0]\n",
    "        result['neg_f1'] = scores[2][1]\n",
    "        result['macro_f1'] = f1_score(true, preds, average = 'macro')\n",
    "        result['micro_f1'] = f1_score(true, preds, average = 'micro')\n",
    "        \n",
    "        print(str(result['classifier']))\n",
    "        print(str(result['test_set']))\n",
    "        print(\"macro F1: \" + str(result['macro_f1']))\n",
    "        print(\"-------------------\")\n",
    "       \n",
    "        classifier = None\n",
    "        tokenizer = None\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "        all_results.append(result.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774ef1cb-cb11-46e8-98bc-a738b48e6fb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ebcfb858-1cfa-4705-8b1f-3d95a189d539",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('results_%d.pkl' %run, 'wb') as handle:\n",
    "    pickle.dump(all_results, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17ef3f62-d46a-44ad-9da8-49fbdc58985b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('sexism_results_%d.pkl' %run, \"rb\") as input_file:\n",
    "    e = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a0edd21-689b-47f7-bc6e-526291d7107e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_results_df = pd.DataFrame(all_results)\n",
    "all_results_df.to_csv(\"flant5_results_sexism_run_%d.csv\" %run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "843aabf0-b59b-4b24-9b4d-737f9d1b63c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>construct</th>\n",
       "      <th>mode</th>\n",
       "      <th>classifier_name</th>\n",
       "      <th>run</th>\n",
       "      <th>feature</th>\n",
       "      <th>classifier</th>\n",
       "      <th>test_set</th>\n",
       "      <th>predictions</th>\n",
       "      <th>pos_precision</th>\n",
       "      <th>neg_precision</th>\n",
       "      <th>pos_recall</th>\n",
       "      <th>neg_recall</th>\n",
       "      <th>pos_f1</th>\n",
       "      <th>neg_f1</th>\n",
       "      <th>macro_f1</th>\n",
       "      <th>micro_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sexism</td>\n",
       "      <td>OG</td>\n",
       "      <td>transformer</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>_models/flant5_sexism_OG_4</td>\n",
       "      <td>in_domain</td>\n",
       "      <td>[0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, ...</td>\n",
       "      <td>0.937943</td>\n",
       "      <td>0.756061</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.843700</td>\n",
       "      <td>0.835846</td>\n",
       "      <td>0.839773</td>\n",
       "      <td>0.839869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sexism</td>\n",
       "      <td>OG</td>\n",
       "      <td>transformer</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>_models/flant5_sexism_OG_4</td>\n",
       "      <td>out_of_domain</td>\n",
       "      <td>[1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "      <td>0.614230</td>\n",
       "      <td>0.612409</td>\n",
       "      <td>0.705000</td>\n",
       "      <td>0.705000</td>\n",
       "      <td>0.656492</td>\n",
       "      <td>0.558217</td>\n",
       "      <td>0.607355</td>\n",
       "      <td>0.613504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sexism</td>\n",
       "      <td>OG</td>\n",
       "      <td>transformer</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>_models/flant5_sexism_OG_4</td>\n",
       "      <td>out_of_domain_2</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.956436</td>\n",
       "      <td>0.249254</td>\n",
       "      <td>0.742316</td>\n",
       "      <td>0.742316</td>\n",
       "      <td>0.835881</td>\n",
       "      <td>0.369878</td>\n",
       "      <td>0.602880</td>\n",
       "      <td>0.739588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sexism</td>\n",
       "      <td>OG</td>\n",
       "      <td>transformer</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>_models/flant5_sexism_OG_4</td>\n",
       "      <td>out_of_domain_3</td>\n",
       "      <td>[1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, ...</td>\n",
       "      <td>0.845180</td>\n",
       "      <td>0.354842</td>\n",
       "      <td>0.625710</td>\n",
       "      <td>0.625710</td>\n",
       "      <td>0.719071</td>\n",
       "      <td>0.457151</td>\n",
       "      <td>0.588111</td>\n",
       "      <td>0.629750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sexism</td>\n",
       "      <td>OG</td>\n",
       "      <td>transformer</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>_models/flant5_sexism_OG_4</td>\n",
       "      <td>hatecheck</td>\n",
       "      <td>[0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>0.347490</td>\n",
       "      <td>0.816000</td>\n",
       "      <td>0.661765</td>\n",
       "      <td>0.661765</td>\n",
       "      <td>0.455696</td>\n",
       "      <td>0.654896</td>\n",
       "      <td>0.555296</td>\n",
       "      <td>0.577603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  construct mode classifier_name  run feature                  classifier  \\\n",
       "0    sexism   OG     transformer    4          _models/flant5_sexism_OG_4   \n",
       "1    sexism   OG     transformer    4          _models/flant5_sexism_OG_4   \n",
       "2    sexism   OG     transformer    4          _models/flant5_sexism_OG_4   \n",
       "3    sexism   OG     transformer    4          _models/flant5_sexism_OG_4   \n",
       "4    sexism   OG     transformer    4          _models/flant5_sexism_OG_4   \n",
       "\n",
       "          test_set                                        predictions  \\\n",
       "0        in_domain  [0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, ...   \n",
       "1    out_of_domain  [1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, ...   \n",
       "2  out_of_domain_2  [0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, ...   \n",
       "3  out_of_domain_3  [1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, ...   \n",
       "4        hatecheck  [0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "   pos_precision  neg_precision  pos_recall  neg_recall    pos_f1    neg_f1  \\\n",
       "0       0.937943       0.756061    0.766667    0.766667  0.843700  0.835846   \n",
       "1       0.614230       0.612409    0.705000    0.705000  0.656492  0.558217   \n",
       "2       0.956436       0.249254    0.742316    0.742316  0.835881  0.369878   \n",
       "3       0.845180       0.354842    0.625710    0.625710  0.719071  0.457151   \n",
       "4       0.347490       0.816000    0.661765    0.661765  0.455696  0.654896   \n",
       "\n",
       "   macro_f1  micro_f1  \n",
       "0  0.839773  0.839869  \n",
       "1  0.607355  0.613504  \n",
       "2  0.602880  0.739588  \n",
       "3  0.588111  0.629750  \n",
       "4  0.555296  0.577603  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "140876db-1f8e-4628-ae6c-b9ec06c81fa8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "abdeca00-e284-451e-9b8d-d7b296acb3f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_196696/1615460453.py:1: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  all_results_df.groupby(['mode', 'test_set', 'classifier_name']).mean()[['macro_f1', 'micro_f1']].unstack()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>macro_f1</th>\n",
       "      <th>micro_f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>classifier_name</th>\n",
       "      <th>transformer</th>\n",
       "      <th>transformer</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mode</th>\n",
       "      <th>test_set</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">CAD</th>\n",
       "      <th>hatecheck</th>\n",
       "      <td>0.576376</td>\n",
       "      <td>0.642436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in_domain</th>\n",
       "      <td>0.818623</td>\n",
       "      <td>0.818627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out_of_domain</th>\n",
       "      <td>0.638734</td>\n",
       "      <td>0.642026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out_of_domain_2</th>\n",
       "      <td>0.609174</td>\n",
       "      <td>0.749657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out_of_domain_3</th>\n",
       "      <td>0.602505</td>\n",
       "      <td>0.648550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">CAD_mixed</th>\n",
       "      <th>hatecheck</th>\n",
       "      <td>0.614798</td>\n",
       "      <td>0.664047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in_domain</th>\n",
       "      <td>0.814423</td>\n",
       "      <td>0.814542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out_of_domain</th>\n",
       "      <td>0.638116</td>\n",
       "      <td>0.640570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out_of_domain_2</th>\n",
       "      <td>0.647582</td>\n",
       "      <td>0.795728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out_of_domain_3</th>\n",
       "      <td>0.618355</td>\n",
       "      <td>0.664600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">OG</th>\n",
       "      <th>hatecheck</th>\n",
       "      <td>0.555296</td>\n",
       "      <td>0.577603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in_domain</th>\n",
       "      <td>0.839773</td>\n",
       "      <td>0.839869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out_of_domain</th>\n",
       "      <td>0.607355</td>\n",
       "      <td>0.613504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out_of_domain_2</th>\n",
       "      <td>0.602880</td>\n",
       "      <td>0.739588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out_of_domain_3</th>\n",
       "      <td>0.588111</td>\n",
       "      <td>0.629750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">aCAD</th>\n",
       "      <th>hatecheck</th>\n",
       "      <td>0.356126</td>\n",
       "      <td>0.359528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in_domain</th>\n",
       "      <td>0.781892</td>\n",
       "      <td>0.783497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out_of_domain</th>\n",
       "      <td>0.575228</td>\n",
       "      <td>0.598370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out_of_domain_2</th>\n",
       "      <td>0.611231</td>\n",
       "      <td>0.798627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out_of_domain_3</th>\n",
       "      <td>0.601993</td>\n",
       "      <td>0.700700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">aCAD_FT</th>\n",
       "      <th>hatecheck</th>\n",
       "      <td>0.558820</td>\n",
       "      <td>0.571709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in_domain</th>\n",
       "      <td>0.809880</td>\n",
       "      <td>0.812092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out_of_domain</th>\n",
       "      <td>0.611488</td>\n",
       "      <td>0.619325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out_of_domain_2</th>\n",
       "      <td>0.607798</td>\n",
       "      <td>0.784592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out_of_domain_3</th>\n",
       "      <td>0.588841</td>\n",
       "      <td>0.677400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">aCAD_GPT</th>\n",
       "      <th>hatecheck</th>\n",
       "      <td>0.587471</td>\n",
       "      <td>0.626719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in_domain</th>\n",
       "      <td>0.807899</td>\n",
       "      <td>0.808007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out_of_domain</th>\n",
       "      <td>0.629167</td>\n",
       "      <td>0.634168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out_of_domain_2</th>\n",
       "      <td>0.625666</td>\n",
       "      <td>0.788101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out_of_domain_3</th>\n",
       "      <td>0.615055</td>\n",
       "      <td>0.664350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             macro_f1    micro_f1\n",
       "classifier_name           transformer transformer\n",
       "mode      test_set                               \n",
       "CAD       hatecheck          0.576376    0.642436\n",
       "          in_domain          0.818623    0.818627\n",
       "          out_of_domain      0.638734    0.642026\n",
       "          out_of_domain_2    0.609174    0.749657\n",
       "          out_of_domain_3    0.602505    0.648550\n",
       "CAD_mixed hatecheck          0.614798    0.664047\n",
       "          in_domain          0.814423    0.814542\n",
       "          out_of_domain      0.638116    0.640570\n",
       "          out_of_domain_2    0.647582    0.795728\n",
       "          out_of_domain_3    0.618355    0.664600\n",
       "OG        hatecheck          0.555296    0.577603\n",
       "          in_domain          0.839773    0.839869\n",
       "          out_of_domain      0.607355    0.613504\n",
       "          out_of_domain_2    0.602880    0.739588\n",
       "          out_of_domain_3    0.588111    0.629750\n",
       "aCAD      hatecheck          0.356126    0.359528\n",
       "          in_domain          0.781892    0.783497\n",
       "          out_of_domain      0.575228    0.598370\n",
       "          out_of_domain_2    0.611231    0.798627\n",
       "          out_of_domain_3    0.601993    0.700700\n",
       "aCAD_FT   hatecheck          0.558820    0.571709\n",
       "          in_domain          0.809880    0.812092\n",
       "          out_of_domain      0.611488    0.619325\n",
       "          out_of_domain_2    0.607798    0.784592\n",
       "          out_of_domain_3    0.588841    0.677400\n",
       "aCAD_GPT  hatecheck          0.587471    0.626719\n",
       "          in_domain          0.807899    0.808007\n",
       "          out_of_domain      0.629167    0.634168\n",
       "          out_of_domain_2    0.625666    0.788101\n",
       "          out_of_domain_3    0.615055    0.664350"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results_df.groupby(['mode', 'test_set', 'classifier_name']).mean()[['macro_f1', 'micro_f1']].unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f206c46a-c3c5-4108-bd24-69c0c683e2c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee99f51-8a1a-4923-8221-7b2291aa6a79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
