{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8e968f8-25f7-40b6-ba23-1142af55e581",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install tqdm\n",
    "#!pip install evaluate\n",
    "#!pip install accelerate -U\n",
    "#!pip install  transformers datasets scipy torch\n",
    "#!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e337dc66-4e0e-435f-9680-6ed3dad6f61d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install evaluate\n",
    "import pandas as pd\n",
    "from transformers import TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "import evaluate\n",
    "#from transformers import AutoTokenizer\n",
    "import os\n",
    "import pandas as pd\n",
    "from transformers import TextClassificationPipeline\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import TextClassificationPipeline\n",
    "from transformers import TrainingArguments\n",
    "from transformers import EarlyStoppingCallback, IntervalStrategy\n",
    "from datasets import Dataset\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "from transformers import set_seed\n",
    "\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "from datasets import concatenate_datasets\n",
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "\n",
    "import torch\n",
    "import gc\n",
    "from numba import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "159d363b-512c-4da8-a63a-9750928b382d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## important settings\n",
    "run = 4\n",
    "runs = 1\n",
    "epochs = 5\n",
    "## model used for experiments\n",
    "\n",
    "model_max_length = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69910fc7-9635-43b0-918c-c4ed25c0eb4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "\n",
    "# Load tokenizer of FLAN-t5-base\n",
    "#tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf827659-5cc8-442e-9dbf-94208e0a98e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "constructs = ['hatespeech']\n",
    "construct_names = [\n",
    "    'hatespeech',\n",
    "    ]\n",
    "perplexity = 10 # 1, 5, 10, 15, 20\n",
    "\n",
    "\n",
    "reverse_label_encode = {'sexism' : {\"1\" : 'sexist', \"0\" : 'non-sexist'},\n",
    "                        'hatespeech' : {\"1\" : 'hate', \"0\" : 'not hate'}\n",
    "                       }\n",
    "            \n",
    "label_encode = {'hatespeech': {'hate' : \"1\", 'not hate': \"0\"},\n",
    "                    'sexism' : {'sexist' : \"1\", 'non-sexist': \"0\"}\n",
    "                   }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae66a636-0e31-4c53-a64a-81a98da630ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "               # ('MNB', MultinomialNB),\n",
    "               #('Linear SVM', LinearSVC),\n",
    "               # ('LR', LogisticRegression),\n",
    "               # ('RF', RandomForestClassifier),\n",
    "               ('transformer', 'transformer')\n",
    "]\n",
    "\n",
    "features = ['_TF-IDF', '_fasttext']\n",
    "\n",
    "modes = {\n",
    "         'OG' : ('original_text', 'original_label'),\n",
    "         'CAD' : ('counterfactual_text', 'counterfactual_label'),\n",
    "         'aCAD' : ('polyjuice', 'polyjuice_label'),\n",
    "         'aCAD_GPT' : ('chatgpt', 'chatgpt_label'),\n",
    "         'aCAD_FT' : ('flant5', 'flant5_label'),\n",
    "         'CAD_mixed' : ('mixed_cad_text', 'mixed_cad_label'),   \n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0dfd9d8-5067-41c8-96a1-2aeb9215134c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "paired_data = {}\n",
    "\n",
    "for construct in construct_names:\n",
    "    train_data_path = '%s' %construct\n",
    "    # paired_data[construct] = pd.read_csv(train_data_path + '/paired_adv_cad_GPT_%d.csv' %(perplexity), sep = '\\t')\n",
    "    paired_data[construct] = pd.read_csv(train_data_path + '/paired_cads_mixed.csv', sep = '\\t')\n",
    "    \n",
    "    paired_data[construct]['polyjuice_id'] = [str(i)+'p' for i in paired_data[construct]['original_id']]\n",
    "    paired_data[construct]['chatgpt_id'] = [str(i)+'gpt' for i in paired_data[construct]['original_id']]\n",
    "    paired_data[construct]['flant5_id'] = [str(i)+'ft' for i in paired_data[construct]['original_id']]\n",
    "    paired_data[construct]['mixed_id'] = [str(i)+'m' for i in paired_data[construct]['original_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c928903c-345a-472c-9ddb-542923c5ce69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hatespeech\n",
      "original_label\n",
      "hate        6524\n",
      "not hate    5767\n",
      "dtype: int64\n",
      "\n",
      "counterfactual_label\n",
      "hate        5780\n",
      "not hate    6511\n",
      "dtype: int64\n",
      "\n",
      "polyjuice_label\n",
      "MAR         5613\n",
      "hate        3282\n",
      "not hate    3396\n",
      "dtype: int64\n",
      "\n",
      "chatgpt_label\n",
      "MAR          179\n",
      "hate        5673\n",
      "not hate    6439\n",
      "dtype: int64\n",
      "\n",
      "flant5_label\n",
      "MAR         1069\n",
      "hate        5136\n",
      "not hate    6086\n",
      "dtype: int64\n",
      "\n",
      "mixed_cad_label\n",
      "MAR         1669\n",
      "hate        4986\n",
      "not hate    5636\n",
      "dtype: int64\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "## print loaded data\n",
    "\n",
    "for construct in construct_names:\n",
    "    print(construct)\n",
    "    print(paired_data[construct].groupby('original_label').size())\n",
    "    print()\n",
    "    print(paired_data[construct].groupby('counterfactual_label').size())\n",
    "    print()\n",
    "    print(paired_data[construct].groupby('polyjuice_label').size())\n",
    "    print()\n",
    "    print(paired_data[construct].groupby('chatgpt_label').size())\n",
    "    print()\n",
    "    print(paired_data[construct].groupby('flant5_label').size())\n",
    "    print()\n",
    "    print(paired_data[construct].groupby('mixed_cad_label').size())\n",
    "    print('---------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87a8ac64-598a-4f3f-9f23-47daa7baec1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_reverse = {'hate' : 'not hate', 'not hate' : 'hate', 'MAR' : 'MAR',\n",
    "                 'sexist' : 'non-sexist', 'non-sexist' : 'sexist'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c3ffdad-8612-4ddb-9f47-f0092d4d75ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize\n",
    "#nltk.download(\"punkt\")\n",
    "\n",
    "# Metric\n",
    "metric = evaluate.combine([\"accuracy\", \"f1\", \"precision\", \"recall\"])\n",
    "\n",
    "# helper function to postprocess text\n",
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [label.strip() for label in labels]\n",
    "\n",
    "    # rougeLSum expects newline after each sentence\n",
    "    preds = [\"\\n\".join(sent_tokenize(pred)) for pred in preds]\n",
    "    labels = [\"\\n\".join(sent_tokenize(label)) for label in labels]\n",
    "    \n",
    "    ## non-expected outputs are mapped to 0 \n",
    "    preds = [\"0\" if ((x != \"0\") and (x != \"1\")) else x for x in preds]\n",
    "    \n",
    "    #print(preds)\n",
    "    #print(labels)\n",
    "    return preds, labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5834b984-8055-4532-b9a7-fcbd798fbb0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "## main optimization function\n",
    "def train_model(data_, construct = 'hatespeech',\n",
    "                features = 'TF-IDF', classifier_type = None,\n",
    "                mode = 'OG', run = 0):\n",
    "    \n",
    "    ## reset\n",
    "    #trainer = None\n",
    "    #results = None\n",
    "    #tokenizer = None\n",
    "    #metric = None\n",
    "    #from transformers import set_seed\n",
    "\n",
    "    set_seed(run)\n",
    "    \n",
    "    ## new metrics and tokenizer are initialized for each hyperparameter run\n",
    "    metric = evaluate.combine([\"accuracy\", \"f1\", \"precision\", \"recall\"])\n",
    "    \n",
    "    \n",
    "    def compute_metrics(eval_preds):\n",
    "        preds, labels = eval_preds\n",
    "        if isinstance(preds, tuple):\n",
    "            preds = preds[0]\n",
    "        decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "        # Replace -100 in the labels as we can't decode them.\n",
    "        labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "        decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "        # Some simple post-processing\n",
    "        decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "        result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "        result = {k: round(v * 100, 4) for k, v in result.items()}\n",
    "        prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "        result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "        return result\n",
    "    \n",
    "    def preprocess_function(sample, padding=\"max_length\"):\n",
    "        max_target_length=3\n",
    "        max_source_length = 512\n",
    "        #print(sample[\"label\"])\n",
    "\n",
    "        # add prefix to the input for t5\n",
    "        inputs = [item for item in sample[\"text\"]]\n",
    "\n",
    "        # tokenize inputs\n",
    "        model_inputs = tokenizer(inputs, max_length=max_source_length, padding=padding, truncation=True)\n",
    "\n",
    "        # Tokenize targets with the `text_target` keyword argument\n",
    "        labels = tokenizer(text_target=sample[\"label\"], max_length=max_target_length, padding=padding, truncation=True)\n",
    "\n",
    "        # If we are padding here, replace all tokenizer.pad_token_id in the labels by -100 when we want to ignore\n",
    "        # padding in the loss.\n",
    "        if padding == \"max_length\":\n",
    "            labels[\"input_ids\"] = [\n",
    "                [(l if l != tokenizer.pad_token_id else -100) for l in label] for label in labels[\"input_ids\"]\n",
    "            ]\n",
    "\n",
    "        model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "        return model_inputs\n",
    "    \n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    \n",
    "    data = data_.copy()\n",
    "    # step 1. stratify and equalize classes (by original labels)\n",
    "    g = data.groupby(modes['OG'][1])\n",
    "    training_data = g.apply(lambda x: x.sample(g.size().min()).reset_index(drop=True))\n",
    "    training_data = training_data.sample(frac=1)\n",
    "    #print(len(training_data))\n",
    "    #print(training_data.head()[\"original_text\"])\n",
    "    \n",
    "    ## DIFFERENT SETTINGS FOR DATA\n",
    "    if mode == 'OG':\n",
    "        training_X = training_data[modes['OG'][0] + features].values\n",
    "        training_y = training_data[modes['OG'][1]].values\n",
    "        \n",
    "        training_data_datamap = [training_data[modes['OG'][0].split('_')[0] + '_id'].values,\n",
    "                                 training_data[modes['OG'][0]].values,\n",
    "                                 training_data[modes['OG'][1]].values,\n",
    "                                 ['original'] * len(training_data[modes['OG'][1]])\n",
    "                                ]\n",
    "    else:\n",
    "        # step 2. keep pos class as is\n",
    "        pos_data = training_data[training_data[modes['OG'][1]] == reverse_label_encode[construct][\"1\"]]\n",
    "        training_X = list(pos_data[modes['OG'][0] + features].values) #adding the OGs\n",
    "        training_y = list(pos_data[modes['OG'][1]].values)\n",
    "            \n",
    "        # Step 3: drop half of the negative data (non-sexist, non-hate)\n",
    "        neg_data = training_data[training_data[modes['OG'][1]] == reverse_label_encode[construct][\"0\"]]\n",
    "        neg_sample_len = len(neg_data)\n",
    "        neg_data = neg_data.sample(n = neg_sample_len//2)\n",
    "        training_X.extend(list(neg_data[modes['OG'][0] + features].values)) #adding the OGs\n",
    "        training_y.extend(list(neg_data[modes['OG'][1]].values))\n",
    "            \n",
    "        # replace with that much counterfactual\n",
    "        neg_cad_data = pos_data#.sample(n = neg_sample_len//2)\n",
    "        # drop the missing CADs (MAR)\n",
    "        neg_cad_data = neg_cad_data[neg_cad_data[modes[mode][1]] != 'MAR']\n",
    "        neg_cad_data = neg_cad_data.sample(n = neg_sample_len//2)\n",
    "        training_X.extend(list(neg_cad_data[modes[mode][0] + features].values)) #adding the CADs\n",
    "        training_y.extend(list(neg_cad_data[modes[mode][1]].values))\n",
    "            \n",
    "        ids = list(pos_data[modes['OG'][0].split('_')[0] + '_id'].values)\n",
    "        ids.extend(list(neg_data[modes['OG'][0].split('_')[0] + '_id'].values))\n",
    "        ids.extend(list(neg_cad_data[modes[mode][0].split('_')[0] + '_id'].values))\n",
    "        \n",
    "        texts = list(pos_data[modes['OG'][0]].values)\n",
    "        texts.extend(list(neg_data[modes['OG'][0]].values))\n",
    "        texts.extend(list(neg_cad_data[modes[mode][0]].values))\n",
    "        \n",
    "        labels = list(pos_data[modes['OG'][1]].values)\n",
    "        labels.extend(list(neg_data[modes['OG'][1]].values))\n",
    "        labels.extend(list(neg_cad_data[modes[mode][1]].values))\n",
    "        \n",
    "        mode_lists = ['original'] * (len(pos_data) + len(neg_data))\n",
    "        mode_lists.extend([modes[mode][1].split('_')[0]] * len(neg_cad_data))\n",
    "        \n",
    "        training_data_datamap = [ids, texts, labels, mode_lists]\n",
    "        \n",
    "    training_data_datamap_df = pd.DataFrame(training_data_datamap).T\n",
    "    training_data_datamap_df.columns = ['id', 'text', 'label', 'data_type']\n",
    "    print('FINAL DIST: ', training_data_datamap_df.groupby('label').size())\n",
    "    \n",
    "    \n",
    "\n",
    "    train_data = []\n",
    "    \n",
    "    for n, text in enumerate(training_X):\n",
    "        train_data.append((text, label_encode[construct][training_y[n]]))\n",
    "    train_df = pd.DataFrame(train_data)\n",
    "    train_df.columns = [\"text\", \"labels\"]\n",
    "    train_df[\"label\"] = train_df[\"labels\"]\n",
    "    dataset = Dataset.from_pandas(train_df)\n",
    "    \n",
    "    #print(train_df.tail())\n",
    "\n",
    "    tokenized_datasets = dataset.map(preprocess_function, batched=True)\n",
    "    #print(f\"Keys of tokenized dataset: {list(tokenized_dataset['train'].features)}\")\n",
    "    #tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "    tokenized_datasets = tokenized_datasets.class_encode_column(\"label\")\n",
    "\n",
    "    ## create splits\n",
    "    split = tokenized_datasets.train_test_split(test_size = 0.2, stratify_by_column=\"label\")\n",
    "    \n",
    "    \n",
    "    split[\"train\"]=split[\"train\"].remove_columns(\"label\")\n",
    "    split[\"train\"]=split[\"train\"].remove_columns(\"text\")\n",
    "    split[\"test\"]=split[\"test\"].remove_columns(\"label\")\n",
    "    split[\"test\"]=split[\"test\"].remove_columns(\"text\")\n",
    "    #print(split[\"train\"][\"input_ids\"][0])\n",
    "    \n",
    "    ## init model\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "    # we want to ignore tokenizer pad token in the loss\n",
    "    label_pad_token_id = -100\n",
    "    \n",
    "    # Data collator\n",
    "    data_collator = DataCollatorForSeq2Seq(\n",
    "        tokenizer,\n",
    "        model=model,\n",
    "        label_pad_token_id=label_pad_token_id,\n",
    "        pad_to_multiple_of=8\n",
    "    )\n",
    "   \n",
    "    ## setup training arguments\n",
    "    training_args = Seq2SeqTrainingArguments(\n",
    "        output_dir='_outflant5/_out_'+str(construct)+\"_\"+str(mode)+\"_\"+str(run),\n",
    "        #evaluation_strategy=\"epoch\",\n",
    "        learning_rate=5e-4,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=16,\n",
    "        \n",
    "        evaluation_strategy=\"no\",\n",
    "        save_strategy=\"epoch\",\n",
    "        save_total_limit=2,\n",
    "        num_train_epochs=epochs,\n",
    "        load_best_model_at_end=False,\n",
    "        weight_decay=0.001,\n",
    "        #save_strategy=\"epoch\",\n",
    "        #do_predict=True,\n",
    "        logging_steps=200,\n",
    "        logging_dir=\"logs\",\n",
    "        skip_memory_metrics=True,\n",
    "        report_to=\"none\",\n",
    "        predict_with_generate=True,\n",
    "        seed=run\n",
    "\n",
    "    )\n",
    "    \n",
    "    \n",
    "    ## setup trainer\n",
    "    trainer =  Seq2SeqTrainer(\n",
    "        args=training_args,\n",
    "        train_dataset=split[\"train\"],\n",
    "        eval_dataset=split[\"test\"],\n",
    "        compute_metrics=compute_metrics,\n",
    "        model=model,\n",
    "        data_collator=data_collator\n",
    "    )\n",
    "    \n",
    "    \n",
    "    trainer.train()\n",
    "    print(str(construct)+\"_\"+str(mode)+\"_\"+str(run))\n",
    "    print(trainer.evaluate())\n",
    "\n",
    "    trainer.save_model(\"_models/flant5_\"+str(construct)+\"_\"+str(mode)+\"_\"+str(run))\n",
    "    \n",
    "    del training_args\n",
    "    \n",
    "    del model\n",
    "    #gc.collect()\n",
    "    del tokenizer\n",
    "    #gc.collect()\n",
    "    del data_collator\n",
    "    #gc.collect()\n",
    "    del trainer\n",
    "    #gc.collect()\n",
    "    del split\n",
    "    gc.collect()\n",
    "    #data_collator = None\n",
    "    #model = None\n",
    "    #trainer = None\n",
    "    #results = None \n",
    "    #tokenizer = None\n",
    "    #metric = None\n",
    "    #split= None\n",
    "    \n",
    "   # gc.collect()\n",
    "    with torch.no_grad():\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    return \"_models/flant5_\"+str(construct)+\"_\"+str(mode)+\"_\"+str(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c110ccd8-2369-4fb5-994e-896865b7daa8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = None\n",
    "trainer = None\n",
    "results = None \n",
    "tokenizer = None\n",
    "metric = None\n",
    "split= None\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed1b11a0-968a-4bd6-a69a-e5299e1417e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#gc.get_objects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0fee50c2-63ed-4ce6-8128-7ba1495e328f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OG\n",
      "FINAL DIST:  label\n",
      "hate        5767\n",
      "not hate    5767\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02fac0966f694fadbd65f2383d67659b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11534 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d268bfc2c4040ab88fd0535d302c22d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/11534 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2885' max='2885' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2885/2885 51:52, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.353400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.157500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.127300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.094700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.086900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.079900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.055200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.049000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.041300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.023100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.021500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.017700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.009600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.007200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hatespeech_OG_4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='145' max='145' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [145/145 01:40]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.17148907482624054, 'eval_accuracy': 92.6745, 'eval_f1': 92.649, 'eval_precision': 93.0131, 'eval_recall': 92.2877, 'eval_gen_len': 2.5036844386649326, 'eval_runtime': 101.4438, 'eval_samples_per_second': 22.742, 'eval_steps_per_second': 1.429, 'epoch': 5.0}\n",
      "CAD\n",
      "FINAL DIST:  label\n",
      "hate        5777\n",
      "not hate    5756\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41f6efd30ab54a0eb3a2bccf836b62d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11533 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aa070988e60446e9b63e423acfd715f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/11533 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2885' max='2885' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2885/2885 51:46, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.310900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.208700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.190000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.149400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.138600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.127600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.090500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.096800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.076900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.050600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.054400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.038900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.028900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.024400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hatespeech_CAD_4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='145' max='145' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [145/145 01:40]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3802478015422821, 'eval_accuracy': 84.9588, 'eval_f1': 85.2026, 'eval_precision': 84.0202, 'eval_recall': 86.4187, 'eval_gen_len': 2.484178586909406, 'eval_runtime': 101.4391, 'eval_samples_per_second': 22.743, 'eval_steps_per_second': 1.429, 'epoch': 5.0}\n",
      "aCAD\n",
      "FINAL DIST:  label\n",
      "hate        5767\n",
      "not hate    5766\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "423fe5e489af4d5eae139a90f3b3a77e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11533 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e43a1a6bea9a4944a4c0229631753104",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/11533 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2885' max='2885' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2885/2885 51:45, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.324000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.257700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.248000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.232900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.228200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.216400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.201000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.200400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.175100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.163300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.177900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.157200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.147800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.138200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hatespeech_aCAD_4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='145' max='145' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [145/145 01:40]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3799019455909729, 'eval_accuracy': 69.4408, 'eval_f1': 71.3298, 'eval_precision': 67.2031, 'eval_recall': 75.9965, 'eval_gen_len': 2.434330299089727, 'eval_runtime': 101.6027, 'eval_samples_per_second': 22.706, 'eval_steps_per_second': 1.427, 'epoch': 5.0}\n",
      "aCAD_GPT\n",
      "FINAL DIST:  label\n",
      "hate        5767\n",
      "not hate    5766\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28799ad9d2804be4872bd2d200712ccb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11533 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35e932a4837c4bc78d3d018ab4c865c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/11533 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2885' max='2885' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2885/2885 51:53, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.232800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.131800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.102700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.056500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.060800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.055500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.027300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.024400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.014600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.008800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.012900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.004000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.004500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.002200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hatespeech_aCAD_GPT_4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='145' max='145' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [145/145 01:40]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2532784640789032, 'eval_accuracy': 92.5444, 'eval_f1': 92.4891, 'eval_precision': 93.2218, 'eval_recall': 91.7678, 'eval_gen_len': 2.507585609016038, 'eval_runtime': 101.6905, 'eval_samples_per_second': 22.686, 'eval_steps_per_second': 1.426, 'epoch': 5.0}\n",
      "aCAD_FT\n",
      "FINAL DIST:  label\n",
      "hate        5767\n",
      "not hate    5766\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb19c5d805d94613bd0f012e0a686041",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11533 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bef7839c796e489aa5c6cea0efa3826d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/11533 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2885' max='2885' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2885/2885 51:50, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.327200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.250500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.228000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.210300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.202800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.196100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.162600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.174800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.163300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.139200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.139700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.125600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.114500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.112600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hatespeech_aCAD_FT_4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='145' max='145' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [145/145 01:40]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.42415347695350647, 'eval_accuracy': 69.3541, 'eval_f1': 70.9173, 'eval_precision': 67.502, 'eval_recall': 74.6967, 'eval_gen_len': 2.446467273515388, 'eval_runtime': 101.7777, 'eval_samples_per_second': 22.667, 'eval_steps_per_second': 1.425, 'epoch': 5.0}\n",
      "CAD_mixed\n",
      "FINAL DIST:  label\n",
      "hate        5769\n",
      "not hate    5764\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21ffcf6a20c246df92d109bc8fa8cfb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11533 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71580112cd6647a68ef84f5179aed58d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/11533 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2885' max='2885' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2885/2885 51:47, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.311300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.223900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.206300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.170100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.174000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.153800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.116300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.125900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.117900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.088500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.090200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.071800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.064600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.066400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hatespeech_CAD_mixed_4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='145' max='145' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [145/145 01:40]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4352492690086365, 'eval_accuracy': 77.8934, 'eval_f1': 78.0928, 'eval_precision': 77.4276, 'eval_recall': 78.7695, 'eval_gen_len': 2.4911140008669266, 'eval_runtime': 101.7339, 'eval_samples_per_second': 22.677, 'eval_steps_per_second': 1.425, 'epoch': 5.0}\n"
     ]
    }
   ],
   "source": [
    "all_models = []\n",
    "## iterate over constructs\n",
    "for construct in constructs:\n",
    "    model = {}\n",
    "    model['construct'] = construct\n",
    "    ## oterate over modes\n",
    "    for mode in modes:\n",
    "        print(mode)\n",
    "        model['mode'] = mode\n",
    "        \n",
    "        ## iterate over classifier\n",
    "        for classifier_name, classifier_type in classifiers:\n",
    "            model['classifier_name'] = classifier_name\n",
    "            ## iterate over number of runs\n",
    "            #for run in range(runs):\n",
    "            model['run'] = run\n",
    "            if classifier_type == 'transformer':\n",
    "                    model['feature'] = ''\n",
    "                \n",
    "            model['classifier'] = train_model(paired_data[construct], construct,\n",
    "                                                features = model['feature'], classifier_type = classifier_type,\n",
    "                                                mode = mode, run = run)\n",
    "            #device = cuda.get_current_device()\n",
    "            #device.reset()\n",
    "            all_models.append(model.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0993cca-0d3c-4195-abc9-55785d32276d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_sets = ['in_domain', 'out_of_domain', \n",
    "             'out_of_domain_2', 'out_of_domain_3', \n",
    "             'out_of_domain_4', \n",
    "             'hatecheck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "610803e8-4e23-4601-8384-d66aef2b9329",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_set_data = {}\n",
    "\n",
    "for construct in construct_names:\n",
    "    test_set_data[construct] = {}\n",
    "    for test_set in test_sets:\n",
    "        test_path = '%s/test/%s.csv' %(construct, test_set)\n",
    "        test_set_data[construct][test_set] = pd.read_csv(test_path, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08049c3b-56b1-4757-9928-aebd9b8242e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, precision_recall_fscore_support, roc_curve, roc_auc_score, f1_score, accuracy_score, recall_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96c4134e-2890-4bc6-a235-edc13c333b14",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'construct': 'hatespeech',\n",
       "  'mode': 'OG',\n",
       "  'classifier_name': 'transformer',\n",
       "  'run': 4,\n",
       "  'feature': '',\n",
       "  'classifier': '_models/flant5_hatespeech_OG_4'},\n",
       " {'construct': 'hatespeech',\n",
       "  'mode': 'CAD',\n",
       "  'classifier_name': 'transformer',\n",
       "  'run': 4,\n",
       "  'feature': '',\n",
       "  'classifier': '_models/flant5_hatespeech_CAD_4'},\n",
       " {'construct': 'hatespeech',\n",
       "  'mode': 'aCAD',\n",
       "  'classifier_name': 'transformer',\n",
       "  'run': 4,\n",
       "  'feature': '',\n",
       "  'classifier': '_models/flant5_hatespeech_aCAD_4'},\n",
       " {'construct': 'hatespeech',\n",
       "  'mode': 'aCAD_GPT',\n",
       "  'classifier_name': 'transformer',\n",
       "  'run': 4,\n",
       "  'feature': '',\n",
       "  'classifier': '_models/flant5_hatespeech_aCAD_GPT_4'},\n",
       " {'construct': 'hatespeech',\n",
       "  'mode': 'aCAD_FT',\n",
       "  'classifier_name': 'transformer',\n",
       "  'run': 4,\n",
       "  'feature': '',\n",
       "  'classifier': '_models/flant5_hatespeech_aCAD_FT_4'},\n",
       " {'construct': 'hatespeech',\n",
       "  'mode': 'CAD_mixed',\n",
       "  'classifier_name': 'transformer',\n",
       "  'run': 4,\n",
       "  'feature': '',\n",
       "  'classifier': '_models/flant5_hatespeech_CAD_mixed_4'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "beca399d-e61f-4bf3-9215-119cb133850b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_models/flant5_hatespeech_OG_4\n",
      "in_domain\n",
      "macro F1: 0.9818174330722533\n",
      "-------------------\n",
      "_models/flant5_hatespeech_OG_4\n",
      "out_of_domain\n",
      "macro F1: 0.653415072624294\n",
      "-------------------\n",
      "_models/flant5_hatespeech_OG_4\n",
      "out_of_domain_2\n",
      "macro F1: 0.6352249049671025\n",
      "-------------------\n",
      "_models/flant5_hatespeech_OG_4\n",
      "out_of_domain_3\n",
      "macro F1: 0.6137355097362628\n",
      "-------------------\n",
      "_models/flant5_hatespeech_OG_4\n",
      "out_of_domain_4\n",
      "macro F1: 0.517419405475631\n",
      "-------------------\n",
      "_models/flant5_hatespeech_OG_4\n",
      "hatecheck\n",
      "macro F1: 0.6920641501372724\n",
      "-------------------\n",
      "_models/flant5_hatespeech_CAD_4\n",
      "in_domain\n",
      "macro F1: 0.9796791443850267\n",
      "-------------------\n",
      "_models/flant5_hatespeech_CAD_4\n",
      "out_of_domain\n",
      "macro F1: 0.7119744398551793\n",
      "-------------------\n",
      "_models/flant5_hatespeech_CAD_4\n",
      "out_of_domain_2\n",
      "macro F1: 0.6284893267651888\n",
      "-------------------\n",
      "_models/flant5_hatespeech_CAD_4\n",
      "out_of_domain_3\n",
      "macro F1: 0.6665223024308244\n",
      "-------------------\n",
      "_models/flant5_hatespeech_CAD_4\n",
      "out_of_domain_4\n",
      "macro F1: 0.5251743058265665\n",
      "-------------------\n",
      "_models/flant5_hatespeech_CAD_4\n",
      "hatecheck\n",
      "macro F1: 0.8115476030982827\n",
      "-------------------\n",
      "_models/flant5_hatespeech_aCAD_4\n",
      "in_domain\n",
      "macro F1: 0.9497139836205704\n",
      "-------------------\n",
      "_models/flant5_hatespeech_aCAD_4\n",
      "out_of_domain_2\n",
      "macro F1: 0.5337030371423961\n",
      "-------------------\n",
      "_models/flant5_hatespeech_aCAD_4\n",
      "out_of_domain_3\n",
      "macro F1: 0.6377537046127768\n",
      "-------------------\n",
      "_models/flant5_hatespeech_aCAD_4\n",
      "out_of_domain_4\n",
      "macro F1: 0.5092845929160665\n",
      "-------------------\n",
      "_models/flant5_hatespeech_aCAD_4\n",
      "hatecheck\n",
      "macro F1: 0.3281123069067207\n",
      "-------------------\n",
      "_models/flant5_hatespeech_aCAD_GPT_4\n",
      "in_domain\n",
      "macro F1: 0.9796698423597403\n",
      "-------------------\n",
      "_models/flant5_hatespeech_aCAD_GPT_4\n",
      "out_of_domain\n",
      "macro F1: 0.6901127883727176\n",
      "-------------------\n",
      "_models/flant5_hatespeech_aCAD_GPT_4\n",
      "out_of_domain_2\n",
      "macro F1: 0.6343375704800988\n",
      "-------------------\n",
      "_models/flant5_hatespeech_aCAD_GPT_4\n",
      "out_of_domain_3\n",
      "macro F1: 0.6232417214319163\n",
      "-------------------\n",
      "_models/flant5_hatespeech_aCAD_GPT_4\n",
      "out_of_domain_4\n",
      "macro F1: 0.5162425985066864\n",
      "-------------------\n",
      "_models/flant5_hatespeech_aCAD_GPT_4\n",
      "hatecheck\n",
      "macro F1: 0.6002924380583955\n",
      "-------------------\n",
      "_models/flant5_hatespeech_aCAD_FT_4\n",
      "in_domain\n",
      "macro F1: 0.958287052342228\n",
      "-------------------\n",
      "_models/flant5_hatespeech_aCAD_FT_4\n",
      "out_of_domain\n",
      "macro F1: 0.6248048739921603\n",
      "-------------------\n",
      "_models/flant5_hatespeech_aCAD_FT_4\n",
      "out_of_domain_2\n",
      "macro F1: 0.5491693957108745\n",
      "-------------------\n",
      "_models/flant5_hatespeech_aCAD_FT_4\n",
      "out_of_domain_3\n",
      "macro F1: 0.5822914067653601\n",
      "-------------------\n",
      "_models/flant5_hatespeech_aCAD_FT_4\n",
      "out_of_domain_4\n",
      "macro F1: 0.5191785099487006\n",
      "-------------------\n",
      "_models/flant5_hatespeech_aCAD_FT_4\n",
      "hatecheck\n",
      "macro F1: 0.516926882355178\n",
      "-------------------\n",
      "_models/flant5_hatespeech_CAD_mixed_4\n",
      "in_domain\n",
      "macro F1: 0.9593478260869566\n",
      "-------------------\n",
      "_models/flant5_hatespeech_CAD_mixed_4\n",
      "out_of_domain\n",
      "macro F1: 0.6791034092948317\n",
      "-------------------\n",
      "_models/flant5_hatespeech_CAD_mixed_4\n",
      "out_of_domain_2\n",
      "macro F1: 0.5957364966311375\n",
      "-------------------\n",
      "_models/flant5_hatespeech_CAD_mixed_4\n",
      "out_of_domain_3\n",
      "macro F1: 0.6032047864316141\n",
      "-------------------\n",
      "_models/flant5_hatespeech_CAD_mixed_4\n",
      "out_of_domain_4\n",
      "macro F1: 0.5256969034316036\n",
      "-------------------\n",
      "_models/flant5_hatespeech_CAD_mixed_4\n",
      "hatecheck\n",
      "macro F1: 0.6235993329628852\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "all_results = []\n",
    "\n",
    "for model in all_models:\n",
    "    result = model.copy()\n",
    "    for test_set in test_sets:\n",
    "        result['test_set'] = test_set\n",
    "        test_data = test_set_data[model['construct']][test_set]\n",
    "        construct = model['construct']\n",
    "        \n",
    "        if model['classifier_name'] == 'transformer':\n",
    "            test_features = list(test_data['text'].values)\n",
    "            \n",
    "            tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "            classifier = AutoModelForSeq2SeqLM.from_pretrained(model['classifier'])\n",
    "            classifier.to('cuda')\n",
    "\n",
    "            preds = []\n",
    "            for x in test_features:\n",
    "                inputs = tokenizer.encode_plus(x, padding='max_length', max_length=512, return_tensors='pt').to('cuda')\n",
    "                outputs = classifier.generate(inputs['input_ids'], attention_mask=inputs['attention_mask'], max_length=3, num_beams=1,do_sample=False)\n",
    "                out = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "                preds.append(out)\n",
    "            \n",
    "            \n",
    "            preds,k = postprocess_text(preds,\"\")\n",
    "    \n",
    "            \n",
    "            true = [label_encode[construct][x] for x in test_set_data[construct][test_set][construct].values]\n",
    "       \n",
    "      \n",
    "        else:\n",
    "            print(\"wrong way\")\n",
    "\n",
    "        \n",
    "        scores = precision_recall_fscore_support(true, preds)\n",
    "        test_data['%s_%s_%d_predictions' %(model['mode'], model['classifier_name'],\n",
    "                                              model['run'])] = preds\n",
    "\n",
    "        \n",
    "        result['predictions'] = preds\n",
    "        result['pos_precision'] = scores[0][0]\n",
    "        result['neg_precision'] = scores[0][1]\n",
    "        result['pos_recall'] = scores[1][0]\n",
    "        result['neg_recall'] = scores[1][0]\n",
    "        result['pos_f1'] = scores[2][0]\n",
    "        result['neg_f1'] = scores[2][1]\n",
    "        result['macro_f1'] = f1_score(true, preds, average = 'macro')\n",
    "        result['micro_f1'] = f1_score(true, preds, average = 'micro')\n",
    "        \n",
    "        print(str(result['classifier']))\n",
    "        print(str(result['test_set']))\n",
    "        print(\"macro F1: \" + str(result['macro_f1']))\n",
    "        print(\"-------------------\")\n",
    "       \n",
    "        classifier = None\n",
    "        tokenizer = None\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "        all_results.append(result.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774ef1cb-cb11-46e8-98bc-a738b48e6fb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ebcfb858-1cfa-4705-8b1f-3d95a189d539",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('hs_results_'+str(run)+'.pkl', 'wb') as handle:\n",
    "    pickle.dump(all_results, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a0edd21-689b-47f7-bc6e-526291d7107e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_results_df = pd.DataFrame(all_results)\n",
    "all_results_df.to_csv('flant5_results_hatespeech_run_'+str(run)+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "843aabf0-b59b-4b24-9b4d-737f9d1b63c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>construct</th>\n",
       "      <th>mode</th>\n",
       "      <th>classifier_name</th>\n",
       "      <th>run</th>\n",
       "      <th>feature</th>\n",
       "      <th>classifier</th>\n",
       "      <th>test_set</th>\n",
       "      <th>predictions</th>\n",
       "      <th>pos_precision</th>\n",
       "      <th>neg_precision</th>\n",
       "      <th>pos_recall</th>\n",
       "      <th>neg_recall</th>\n",
       "      <th>pos_f1</th>\n",
       "      <th>neg_f1</th>\n",
       "      <th>macro_f1</th>\n",
       "      <th>micro_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hatespeech</td>\n",
       "      <td>OG</td>\n",
       "      <td>transformer</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>_models/flant5_hatespeech_OG_4</td>\n",
       "      <td>in_domain</td>\n",
       "      <td>[1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, ...</td>\n",
       "      <td>0.980645</td>\n",
       "      <td>0.982979</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.981701</td>\n",
       "      <td>0.981934</td>\n",
       "      <td>0.981817</td>\n",
       "      <td>0.981818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hatespeech</td>\n",
       "      <td>OG</td>\n",
       "      <td>transformer</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>_models/flant5_hatespeech_OG_4</td>\n",
       "      <td>out_of_domain</td>\n",
       "      <td>[1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, ...</td>\n",
       "      <td>0.745734</td>\n",
       "      <td>0.578257</td>\n",
       "      <td>0.590648</td>\n",
       "      <td>0.590648</td>\n",
       "      <td>0.659192</td>\n",
       "      <td>0.647638</td>\n",
       "      <td>0.653415</td>\n",
       "      <td>0.653511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hatespeech</td>\n",
       "      <td>OG</td>\n",
       "      <td>transformer</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>_models/flant5_hatespeech_OG_4</td>\n",
       "      <td>out_of_domain_2</td>\n",
       "      <td>[1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, ...</td>\n",
       "      <td>0.682150</td>\n",
       "      <td>0.600554</td>\n",
       "      <td>0.751149</td>\n",
       "      <td>0.751149</td>\n",
       "      <td>0.714989</td>\n",
       "      <td>0.555461</td>\n",
       "      <td>0.635225</td>\n",
       "      <td>0.652667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hatespeech</td>\n",
       "      <td>OG</td>\n",
       "      <td>transformer</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>_models/flant5_hatespeech_OG_4</td>\n",
       "      <td>out_of_domain_3</td>\n",
       "      <td>[1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, ...</td>\n",
       "      <td>0.844026</td>\n",
       "      <td>0.378640</td>\n",
       "      <td>0.709908</td>\n",
       "      <td>0.709908</td>\n",
       "      <td>0.771179</td>\n",
       "      <td>0.456292</td>\n",
       "      <td>0.613736</td>\n",
       "      <td>0.677911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hatespeech</td>\n",
       "      <td>OG</td>\n",
       "      <td>transformer</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>_models/flant5_hatespeech_OG_4</td>\n",
       "      <td>out_of_domain_4</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.825147</td>\n",
       "      <td>0.221851</td>\n",
       "      <td>0.878355</td>\n",
       "      <td>0.878355</td>\n",
       "      <td>0.850920</td>\n",
       "      <td>0.183919</td>\n",
       "      <td>0.517419</td>\n",
       "      <td>0.747894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    construct mode classifier_name  run feature  \\\n",
       "0  hatespeech   OG     transformer    4           \n",
       "1  hatespeech   OG     transformer    4           \n",
       "2  hatespeech   OG     transformer    4           \n",
       "3  hatespeech   OG     transformer    4           \n",
       "4  hatespeech   OG     transformer    4           \n",
       "\n",
       "                       classifier         test_set  \\\n",
       "0  _models/flant5_hatespeech_OG_4        in_domain   \n",
       "1  _models/flant5_hatespeech_OG_4    out_of_domain   \n",
       "2  _models/flant5_hatespeech_OG_4  out_of_domain_2   \n",
       "3  _models/flant5_hatespeech_OG_4  out_of_domain_3   \n",
       "4  _models/flant5_hatespeech_OG_4  out_of_domain_4   \n",
       "\n",
       "                                         predictions  pos_precision  \\\n",
       "0  [1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, ...       0.980645   \n",
       "1  [1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, ...       0.745734   \n",
       "2  [1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, ...       0.682150   \n",
       "3  [1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, ...       0.844026   \n",
       "4  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...       0.825147   \n",
       "\n",
       "   neg_precision  pos_recall  neg_recall    pos_f1    neg_f1  macro_f1  \\\n",
       "0       0.982979    0.982759    0.982759  0.981701  0.981934  0.981817   \n",
       "1       0.578257    0.590648    0.590648  0.659192  0.647638  0.653415   \n",
       "2       0.600554    0.751149    0.751149  0.714989  0.555461  0.635225   \n",
       "3       0.378640    0.709908    0.709908  0.771179  0.456292  0.613736   \n",
       "4       0.221851    0.878355    0.878355  0.850920  0.183919  0.517419   \n",
       "\n",
       "   micro_f1  \n",
       "0  0.981818  \n",
       "1  0.653511  \n",
       "2  0.652667  \n",
       "3  0.677911  \n",
       "4  0.747894  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "abdeca00-e284-451e-9b8d-d7b296acb3f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_223713/1615460453.py:1: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  all_results_df.groupby(['mode', 'test_set', 'classifier_name']).mean()[['macro_f1', 'micro_f1']].unstack()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>macro_f1</th>\n",
       "      <th>micro_f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>classifier_name</th>\n",
       "      <th>transformer</th>\n",
       "      <th>transformer</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mode</th>\n",
       "      <th>test_set</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">CAD</th>\n",
       "      <th>hatecheck</th>\n",
       "      <td>0.811548</td>\n",
       "      <td>0.825107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in_domain</th>\n",
       "      <td>0.979679</td>\n",
       "      <td>0.979679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out_of_domain</th>\n",
       "      <td>0.711974</td>\n",
       "      <td>0.714679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out_of_domain_2</th>\n",
       "      <td>0.628489</td>\n",
       "      <td>0.638000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out_of_domain_3</th>\n",
       "      <td>0.666522</td>\n",
       "      <td>0.749720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out_of_domain_4</th>\n",
       "      <td>0.525174</td>\n",
       "      <td>0.757602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">CAD_mixed</th>\n",
       "      <th>hatecheck</th>\n",
       "      <td>0.623599</td>\n",
       "      <td>0.623927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in_domain</th>\n",
       "      <td>0.959348</td>\n",
       "      <td>0.959358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out_of_domain</th>\n",
       "      <td>0.679103</td>\n",
       "      <td>0.685309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out_of_domain_2</th>\n",
       "      <td>0.595736</td>\n",
       "      <td>0.638000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out_of_domain_3</th>\n",
       "      <td>0.603205</td>\n",
       "      <td>0.712225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out_of_domain_4</th>\n",
       "      <td>0.525697</td>\n",
       "      <td>0.784154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">OG</th>\n",
       "      <th>hatecheck</th>\n",
       "      <td>0.692064</td>\n",
       "      <td>0.719957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in_domain</th>\n",
       "      <td>0.981817</td>\n",
       "      <td>0.981818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out_of_domain</th>\n",
       "      <td>0.653415</td>\n",
       "      <td>0.653511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out_of_domain_2</th>\n",
       "      <td>0.635225</td>\n",
       "      <td>0.652667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out_of_domain_3</th>\n",
       "      <td>0.613736</td>\n",
       "      <td>0.677911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out_of_domain_4</th>\n",
       "      <td>0.517419</td>\n",
       "      <td>0.747894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">aCAD</th>\n",
       "      <th>hatecheck</th>\n",
       "      <td>0.328112</td>\n",
       "      <td>0.366148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in_domain</th>\n",
       "      <td>0.949714</td>\n",
       "      <td>0.949733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out_of_domain</th>\n",
       "      <td>0.670784</td>\n",
       "      <td>0.683385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out_of_domain_2</th>\n",
       "      <td>0.533703</td>\n",
       "      <td>0.598000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out_of_domain_3</th>\n",
       "      <td>0.637754</td>\n",
       "      <td>0.735251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out_of_domain_4</th>\n",
       "      <td>0.509285</td>\n",
       "      <td>0.765025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">aCAD_FT</th>\n",
       "      <th>hatecheck</th>\n",
       "      <td>0.516927</td>\n",
       "      <td>0.520118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in_domain</th>\n",
       "      <td>0.958287</td>\n",
       "      <td>0.958289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out_of_domain</th>\n",
       "      <td>0.624805</td>\n",
       "      <td>0.633852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out_of_domain_2</th>\n",
       "      <td>0.549169</td>\n",
       "      <td>0.610333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out_of_domain_3</th>\n",
       "      <td>0.582291</td>\n",
       "      <td>0.685571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out_of_domain_4</th>\n",
       "      <td>0.519179</td>\n",
       "      <td>0.726338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">aCAD_GPT</th>\n",
       "      <th>hatecheck</th>\n",
       "      <td>0.600292</td>\n",
       "      <td>0.600322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in_domain</th>\n",
       "      <td>0.979670</td>\n",
       "      <td>0.979679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out_of_domain</th>\n",
       "      <td>0.690113</td>\n",
       "      <td>0.690135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out_of_domain_2</th>\n",
       "      <td>0.634338</td>\n",
       "      <td>0.634667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out_of_domain_3</th>\n",
       "      <td>0.623242</td>\n",
       "      <td>0.694306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out_of_domain_4</th>\n",
       "      <td>0.516243</td>\n",
       "      <td>0.652962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             macro_f1    micro_f1\n",
       "classifier_name           transformer transformer\n",
       "mode      test_set                               \n",
       "CAD       hatecheck          0.811548    0.825107\n",
       "          in_domain          0.979679    0.979679\n",
       "          out_of_domain      0.711974    0.714679\n",
       "          out_of_domain_2    0.628489    0.638000\n",
       "          out_of_domain_3    0.666522    0.749720\n",
       "          out_of_domain_4    0.525174    0.757602\n",
       "CAD_mixed hatecheck          0.623599    0.623927\n",
       "          in_domain          0.959348    0.959358\n",
       "          out_of_domain      0.679103    0.685309\n",
       "          out_of_domain_2    0.595736    0.638000\n",
       "          out_of_domain_3    0.603205    0.712225\n",
       "          out_of_domain_4    0.525697    0.784154\n",
       "OG        hatecheck          0.692064    0.719957\n",
       "          in_domain          0.981817    0.981818\n",
       "          out_of_domain      0.653415    0.653511\n",
       "          out_of_domain_2    0.635225    0.652667\n",
       "          out_of_domain_3    0.613736    0.677911\n",
       "          out_of_domain_4    0.517419    0.747894\n",
       "aCAD      hatecheck          0.328112    0.366148\n",
       "          in_domain          0.949714    0.949733\n",
       "          out_of_domain      0.670784    0.683385\n",
       "          out_of_domain_2    0.533703    0.598000\n",
       "          out_of_domain_3    0.637754    0.735251\n",
       "          out_of_domain_4    0.509285    0.765025\n",
       "aCAD_FT   hatecheck          0.516927    0.520118\n",
       "          in_domain          0.958287    0.958289\n",
       "          out_of_domain      0.624805    0.633852\n",
       "          out_of_domain_2    0.549169    0.610333\n",
       "          out_of_domain_3    0.582291    0.685571\n",
       "          out_of_domain_4    0.519179    0.726338\n",
       "aCAD_GPT  hatecheck          0.600292    0.600322\n",
       "          in_domain          0.979670    0.979679\n",
       "          out_of_domain      0.690113    0.690135\n",
       "          out_of_domain_2    0.634338    0.634667\n",
       "          out_of_domain_3    0.623242    0.694306\n",
       "          out_of_domain_4    0.516243    0.652962"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results_df.groupby(['mode', 'test_set', 'classifier_name']).mean()[['macro_f1', 'micro_f1']].unstack()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
