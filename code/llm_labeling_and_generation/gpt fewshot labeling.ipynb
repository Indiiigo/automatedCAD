{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "close-swimming",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "authorized-danger",
   "metadata": {},
   "outputs": [],
   "source": [
    "construct_names = ['sexism', 'hatespeech']\n",
    "construct = 'hatespeech'\n",
    "pos_label = 'hate'\n",
    "neg_label = 'not hate'\n",
    "\n",
    "construct = 'sexism'\n",
    "pos_label = 'sexist'\n",
    "neg_label = 'non-sexist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "amino-inquiry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cultural-fighter",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_key = \"\" # enter your openAI key\n",
    "\n",
    "# list models\n",
    "models = openai.Model.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "hired-providence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# completion = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\", messages=[{\"role\": \"user\", \"content\": \"Hello world!\"}],n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latin-geography",
   "metadata": {},
   "source": [
    "## Prompt Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "usual-worst",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt_label_sexism(original_sentence):\n",
    "    \n",
    "    prompt = 'Your task is to annotate if a piece of text is sexist or not. Read on for detailed explanations. \\\n",
    "            Something can be sexist: \\\n",
    "            because of its content (what the speaker believes) \\\n",
    "            because of its phrasing (because of the speaker’s choice of words) \\\n",
    "            Sexism due to content. A message may be sexist because of its content--in other words, because of what the speaker believes. For example, the speaker may express sexist attitudes towards gender inequality, either endorsing it (e.g. “some jobs are best left to men”), or antagonizing it (e.g. “the pay gap between genders does not exist, feminists should stop complaining”). Also, the speaker may express stereotypes (how genders are traditionally seen and compared to each other) and behavioral expectations (how individuals of a gender should behave according to traditional views). Sexism may also include positive stereotypes (e.g. “women are the best home cooks”), or target  men (e.g., “men should not cry”)! \\\n",
    "            Sexism due to phrasing. A message may be sexist simply because of how the speaker phrases it--independently from what general beliefs or attitudes the speaker holds. A message is sexist, for example, when it contains attacks, foul language, or derogatory depictions directed towards individuals because of their gender, e.g. by means of name-calling (\"you bitch\"), attacks (\"I\\'m going to kick her back to the kitchen\"), objectification (\"She\\'s stupid but I\\'d still do her\"), inflammatory messages (\"burn all women\"). However, just because a message is aggressive or uses offensive language does not mean that it is sexist! \\\n",
    "            Sexist Examples: \\\n",
    "            “So I wore a dress and wig while bartending and when people asked what my costume was I said a bad driver #dassexist.” This post is sexist because it espouses gendered stereotypes, that women are allegedly not good at driving \\\n",
    "            “You’re a stupid bitch and I hope you die.” This post is sexist because of its phrasing, it contains a gendered slur (‘bitch’). \\\n",
    "            “Women’s sacrifices continue to ensure the future of this country’s sons.” This post espouses benevolent sexism. While such a sentiment might appear benign, benevolent sexism glorifies women and sees their worth only as extensions of their male relatives. \\\n",
    "            Non-sexist Examples \\\n",
    "            “F*ck you Jane ur so stupid” the content is offensive and Jane, the target, is likely a woman; however the message is not clearly sexist because it is unclear if the speaker’s animosity is because of Jane’s gender \\\n",
    "            With these instructions in mind and a piece of text, please reply with either of the three options and nothing else: 1) sexist, 2) non-sexist, 3) can\\'t say. Please use the last option as little as possible and if you do, provide a one sentence explanation. Do not give an explanation if you pick \\'sexist\\' or \\'non-sexist\\'. We are ready to begin now. Is this sentence sexist based on the past guidelines: ' + original_sentence \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "polished-daisy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt_label_hatespeech(original_sentence):\n",
    "    \n",
    "    prompt = 'In this task you have to determine if a piece of text contains hate speech or not. \\\n",
    "            The concept of hate speech refers to language or expression that aims to insult, offend, or threaten individuals or groups based on their identity. Different platforms, institutions, and scholars have offered slightly different definitions of hate speech. However, they share some commonalities, including that hate speech involves expressing something negative, such as contempt, disparagement, derogation, demonization, harm, or bias. The target of hate speech is the identity of a group, which can be based on ethnic origin, religion, gender, sexual orientation, race, ethnicity, nationality, or other characteristics.\\\n",
    "            Read the text carefully and decide if it contains hate speech.\\\n",
    "            If the text degrades, threatens, dehumanizes, or insults someone based on their race, religion, gender, sexual orientation, or any other protected characteristic, then mark it as hate speech.\\\n",
    "            If the text does not contain any hate speech, then mark it as not hateful.\\\n",
    "            Consider the context, speaker\\'s intent, and audience, as hate speech can be explicit or implicit and can include sarcasm, humor, or irony.\\\n",
    "            If you are unsure whether a text contains hate speech, err on the side of caution and label it as hateful.\\\n",
    "            Aim for accuracy and consistency in your labeling.\\\n",
    "            Examples of content containing hate speech:\\\n",
    "            \"All Muslims are terrorists.\" This post contains hate speech because it unfairly degrades an entire group of people based on their religion.\\\n",
    "            “I\\m a huge fan of those that overtly express what we all think: jews are a plague and not welcome in our country.” This post contains hate speech because it promotes anti-Semitic beliefs while dehumanizing Jewish people.\\\n",
    "            \"Transgender people are sick and perverted.\" This post contains hate speech because it stigmatizes a marginalized group of people based on their gender identity.\\\n",
    "            Examples of content not containing hate speech:\\\n",
    "            “I called him out for calling the new student a ‘tranny’.” This is counterspeech, i.e., it opposes the use of transphobic slurs rather than uses them to denigrate others.\\\n",
    "            With these instructions in mind and a piece of text, please reply with either of the three options and nothing else: 1) hate, 2) not hate, 3) can\\'t say. Please use the last option as little as possible and if you do, provide a one sentence explanation. We are ready to begin now. Does this sentence contain hate speech based on the past guidelines: ' + original_sentence \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "premium-daily",
   "metadata": {},
   "outputs": [],
   "source": [
    "## test\n",
    "test_text = \"women are capable of commentating on football matches\" #\"women are weak and belong in the kitchen\"\n",
    "# result = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\",\n",
    "#                                       messages=[{\"role\": \"user\", \"content\": create_prompt_label_hatespeech(test_text)}],\n",
    "#                                       n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intellectual-payroll",
   "metadata": {},
   "source": [
    "## load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "steady-squad",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sets = ['in_domain', 'out_of_domain', \n",
    "             'out_of_domain_2', 'out_of_domain_3',# 'out_of_domain_4', \n",
    "             'hatecheck'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "powered-alfred",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_data = {}\n",
    "\n",
    "for construct in construct_names:\n",
    "    test_set_data[construct] = {}\n",
    "    for test_set in test_sets:\n",
    "        test_path = '../../../data/data/%s/test/%s.csv' %(construct, test_set)\n",
    "        test_set_data[construct][test_set] = pd.read_csv(test_path, sep = '\\t').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "moved-alfred",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## do once and save\n",
    "\n",
    "# for test_set in test_set_data['sexism']:\n",
    "#     results = []\n",
    "#     for _, row in test_set_data['sexism'][test_set].iterrows():\n",
    "#         result = []\n",
    "#         try:\n",
    "#             responses = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\", messages=[{\"role\": \"user\", \"content\": create_prompt_label_sexism(row['text'])}],n=3)\n",
    "#         except:\n",
    "#             time.sleep(60)\n",
    "#             responses = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\", messages=[{\"role\": \"user\", \"content\": create_prompt_label_sexism(row['text'])}],n=3)\n",
    "#         for response in responses['choices']:\n",
    "#             result.append(response['message']['content'])\n",
    "#         results.append(result)\n",
    "#     test_set_data['sexism'][test_set]['chatgpt_labels'] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "initial-heavy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../../designed_data/sexism_chatgpt_labels.pickle', 'wb') as handle:\n",
    "#     pickle.dump(test_set_data['sexism'], handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('../../designed_data/sexism_chatgpt_labels_all.pickle', 'rb') as handle:\n",
    "    test_set_data['sexism'] = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "hispanic-carter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['in_domain', 'out_of_domain', 'hatecheck', 'out_of_domain_2', 'out_of_domain_3'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_data['sexism'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "physical-dealing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remaining_test_sets = [#'in_domain', 'out_of_domain', \n",
    "#              'out_of_domain_2', 'out_of_domain_3',# 'out_of_domain_4', \n",
    "#              #'hatecheck'\n",
    "# ]\n",
    "\n",
    "# for construct in construct_names:\n",
    "#     for test_set in remaining_test_sets:\n",
    "#         test_path = '../../../data/data/%s/test/%s.csv' %(construct, test_set)\n",
    "#         test_set_data[construct][test_set] = pd.read_csv(test_path, sep = '\\t')#.head(10)\n",
    "        \n",
    "# test_set_data['sexism'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "divided-custody",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## do once for the remaining and save\n",
    "\n",
    "# for test_set in remaining_test_sets:\n",
    "#     results = []\n",
    "#     for _, row in tqdm(test_set_data['sexism'][test_set].iterrows(), total=test_set_data['sexism'][test_set].shape[0]):\n",
    "#         result = []\n",
    "#         try:\n",
    "#             responses = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\",\n",
    "#                                                      messages=[{\"role\": \"user\",\n",
    "#                                                                 \"content\": create_prompt_label_sexism(row['text'])}],n=3)\n",
    "#         except:\n",
    "#             time.sleep(60)\n",
    "#             try:\n",
    "#                 responses = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\",\n",
    "#                                                      messages=[{\"role\": \"user\",\n",
    "#                                                                 \"content\": create_prompt_label_sexism(row['text'])}],n=3)\n",
    "#             except:\n",
    "#                 time.sleep(15*60)\n",
    "#         for response in responses['choices']:\n",
    "#             result.append(response['message']['content'])\n",
    "#         results.append(result)\n",
    "#     test_set_data['sexism'][test_set]['chatgpt_labels'] = results\n",
    "    \n",
    "# with open('../../designed_data/sexism_chatgpt_labels_all.pickle', 'wb') as handle:\n",
    "#     pickle.dump(test_set_data['sexism'], handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "colonial-pound",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>text</th>\n",
       "      <th>sexism</th>\n",
       "      <th>chatgpt_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sexism2022_english-9609</td>\n",
       "      <td>In Nigeria, if you rape a woman, the men rape ...</td>\n",
       "      <td>non-sexist</td>\n",
       "      <td>[Sexist. This message contains violent and der...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sexism2022_english-16993</td>\n",
       "      <td>Then, she's a keeper. 😉</td>\n",
       "      <td>non-sexist</td>\n",
       "      <td>[Sexist., Sexist., Sexist.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sexism2022_english-13149</td>\n",
       "      <td>This is like the Metallica video where the poo...</td>\n",
       "      <td>non-sexist</td>\n",
       "      <td>[Non-sexist., Non-sexist., Non-sexist.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sexism2022_english-13021</td>\n",
       "      <td>woman?</td>\n",
       "      <td>non-sexist</td>\n",
       "      <td>[Can't say. There is no context or surrounding...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sexism2022_english-966</td>\n",
       "      <td>I bet she wished she had a gun</td>\n",
       "      <td>non-sexist</td>\n",
       "      <td>[Can't say. The sentence is ambiguous and lack...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>sexism2022_english-5228</td>\n",
       "      <td>girls really get fucked almost every weekend ?</td>\n",
       "      <td>non-sexist</td>\n",
       "      <td>[sexist, Sexist., Sexist.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>sexism2022_english-10140</td>\n",
       "      <td>The hatred for moslems are Reasonable and Just...</td>\n",
       "      <td>non-sexist</td>\n",
       "      <td>[Sexist., Sexist., Sexist.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>sexism2022_english-9726</td>\n",
       "      <td>Now this is a woman who gets it. 👆</td>\n",
       "      <td>non-sexist</td>\n",
       "      <td>[Sexist., Sexist., Sexist.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>sexism2022_english-13365</td>\n",
       "      <td>“American Idol” finalist [USER] said nothing i...</td>\n",
       "      <td>non-sexist</td>\n",
       "      <td>[Non-sexist., Non-sexist., Non-sexist.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>sexism2022_english-3523</td>\n",
       "      <td>this bi--th should be stoped she's the rapist</td>\n",
       "      <td>sexist</td>\n",
       "      <td>[Sexist., sexist, Sexist.]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            _id  \\\n",
       "0       sexism2022_english-9609   \n",
       "1      sexism2022_english-16993   \n",
       "2      sexism2022_english-13149   \n",
       "3      sexism2022_english-13021   \n",
       "4        sexism2022_english-966   \n",
       "...                         ...   \n",
       "19995   sexism2022_english-5228   \n",
       "19996  sexism2022_english-10140   \n",
       "19997   sexism2022_english-9726   \n",
       "19998  sexism2022_english-13365   \n",
       "19999   sexism2022_english-3523   \n",
       "\n",
       "                                                    text      sexism  \\\n",
       "0      In Nigeria, if you rape a woman, the men rape ...  non-sexist   \n",
       "1                                Then, she's a keeper. 😉  non-sexist   \n",
       "2      This is like the Metallica video where the poo...  non-sexist   \n",
       "3                                                 woman?  non-sexist   \n",
       "4                         I bet she wished she had a gun  non-sexist   \n",
       "...                                                  ...         ...   \n",
       "19995     girls really get fucked almost every weekend ?  non-sexist   \n",
       "19996  The hatred for moslems are Reasonable and Just...  non-sexist   \n",
       "19997                 Now this is a woman who gets it. 👆  non-sexist   \n",
       "19998  “American Idol” finalist [USER] said nothing i...  non-sexist   \n",
       "19999      this bi--th should be stoped she's the rapist      sexist   \n",
       "\n",
       "                                          chatgpt_labels  \n",
       "0      [Sexist. This message contains violent and der...  \n",
       "1                            [Sexist., Sexist., Sexist.]  \n",
       "2                [Non-sexist., Non-sexist., Non-sexist.]  \n",
       "3      [Can't say. There is no context or surrounding...  \n",
       "4      [Can't say. The sentence is ambiguous and lack...  \n",
       "...                                                  ...  \n",
       "19995                         [sexist, Sexist., Sexist.]  \n",
       "19996                        [Sexist., Sexist., Sexist.]  \n",
       "19997                        [Sexist., Sexist., Sexist.]  \n",
       "19998            [Non-sexist., Non-sexist., Non-sexist.]  \n",
       "19999                         [Sexist., sexist, Sexist.]  \n",
       "\n",
       "[20000 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_data['sexism']['out_of_domain_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "entire-campaign",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_data_unavail = {'sexism' : {}, 'hatespeech' : {}}\n",
    "for test_set in test_set_data['sexism']:\n",
    "    test_set_data_unavail['sexism'][test_set] = test_set_data['sexism'][test_set].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "choice-stationery",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string \n",
    "\n",
    "count_no_label = {}\n",
    "\n",
    "for test_set in test_set_data['sexism'].keys():\n",
    "    count_no_label[test_set] = 0\n",
    "    results = []\n",
    "    results_un = []\n",
    "    \n",
    "    for _, row in test_set_data['sexism'][test_set].iterrows():\n",
    "        label = row['chatgpt_labels'][0].lower().translate(str.maketrans('', '', string.punctuation))\n",
    "        label = label.split(' ')[0]\n",
    "        label_un = row['chatgpt_labels'][0].lower().translate(str.maketrans('', '', string.punctuation))\n",
    "        label_un = label_un.split(' ')[0]\n",
    "    \n",
    "        if label == 'nonsexist':\n",
    "            label = 'non-sexist'\n",
    "            label_un = 'non-sexist'\n",
    "        elif label == 'sexis' or label == 'benevolent':\n",
    "            label = 'sexist'\n",
    "            label_un = 'sexist'\n",
    "        \n",
    "        if label != 'sexist' and label != 'non-sexist':\n",
    "            label_un = 'unavailable'\n",
    "            label = 'non-sexist'\n",
    "            count_no_label[test_set] += 1\n",
    "    \n",
    "        results.append(label)\n",
    "        results_un.append(label_un)\n",
    "    \n",
    "    test_set_data['sexism'][test_set]['chatgpt_label_aggregate'] = results\n",
    "    test_set_data_unavail['sexism'][test_set]['chatgpt_label_aggregate'] = results_un\n",
    "    #[test_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "twenty-aspect",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('in_domain', 0.028594771241830064),\n",
       " ('out_of_domain', 0.03143189755529686),\n",
       " ('hatecheck', 0.003929273084479371),\n",
       " ('out_of_domain_2', 0.11258581235697941),\n",
       " ('out_of_domain_3', 0.055)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(i, count_no_label[i]/len(test_set_data['sexism'][i])) for i in count_no_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "freelance-worker",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'unavailable' in results_un"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "authorized-coral",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'unavailable' in test_set_data['sexism'][test_set]['chatgpt_label_aggregate'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "functioning-philosophy",
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_set in test_set_data_unavail['sexism'].keys():\n",
    "    test_set_data_unavail['sexism'][test_set] = test_set_data_unavail['sexism'][test_set][test_set_data_unavail['sexism'][test_set]['chatgpt_label_aggregate'] \\\n",
    "                                                                                          != 'unavailable'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "frozen-mozambique",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_domain\n",
      "False\n",
      "False\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.92      0.60      0.72       690\n",
      "      sexist       0.64      0.93      0.76       534\n",
      "\n",
      "    accuracy                           0.74      1224\n",
      "   macro avg       0.78      0.77      0.74      1224\n",
      "weighted avg       0.80      0.74      0.74      1224\n",
      "\n",
      "out_of_domain\n",
      "False\n",
      "False\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.79      0.61      0.69      1800\n",
      "      sexist       0.66      0.82      0.73      1636\n",
      "\n",
      "    accuracy                           0.71      3436\n",
      "   macro avg       0.73      0.72      0.71      3436\n",
      "weighted avg       0.73      0.71      0.71      3436\n",
      "\n",
      "hatecheck\n",
      "False\n",
      "False\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       1.00      0.52      0.69       136\n",
      "      sexist       0.85      1.00      0.92       373\n",
      "\n",
      "    accuracy                           0.87       509\n",
      "   macro avg       0.93      0.76      0.80       509\n",
      "weighted avg       0.89      0.87      0.86       509\n",
      "\n",
      "out_of_domain_2\n",
      "False\n",
      "False\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.98      0.74      0.84      5856\n",
      "      sexist       0.28      0.86      0.42       699\n",
      "\n",
      "    accuracy                           0.75      6555\n",
      "   macro avg       0.63      0.80      0.63      6555\n",
      "weighted avg       0.90      0.75      0.80      6555\n",
      "\n",
      "out_of_domain_3\n",
      "False\n",
      "False\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.97      0.38      0.55     15146\n",
      "      sexist       0.33      0.97      0.50      4854\n",
      "\n",
      "    accuracy                           0.52     20000\n",
      "   macro avg       0.65      0.67      0.52     20000\n",
      "weighted avg       0.82      0.52      0.54     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, precision_recall_fscore_support, roc_curve, f1_score, accuracy_score\n",
    "for test_set in test_set_data['sexism']:\n",
    "    print(test_set)\n",
    "    print('unavailable' in test_set_data['sexism'][test_set]['chatgpt_label_aggregate'].values)\n",
    "    print('unavailable' in test_set_data['sexism'][test_set]['sexism'].values)\n",
    "    print(classification_report(test_set_data['sexism'][test_set]['sexism'],\n",
    "                                test_set_data['sexism'][test_set]['chatgpt_label_aggregate']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "packed-wrestling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_domain\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.94      0.58      0.72       664\n",
      "      sexist       0.64      0.95      0.77       525\n",
      "\n",
      "    accuracy                           0.74      1189\n",
      "   macro avg       0.79      0.77      0.74      1189\n",
      "weighted avg       0.81      0.74      0.74      1189\n",
      "\n",
      "out_of_domain\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.80      0.60      0.68      1718\n",
      "      sexist       0.66      0.84      0.74      1610\n",
      "\n",
      "    accuracy                           0.71      3328\n",
      "   macro avg       0.73      0.72      0.71      3328\n",
      "weighted avg       0.73      0.71      0.71      3328\n",
      "\n",
      "hatecheck\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       1.00      0.51      0.68       134\n",
      "      sexist       0.85      1.00      0.92       373\n",
      "\n",
      "    accuracy                           0.87       507\n",
      "   macro avg       0.93      0.76      0.80       507\n",
      "weighted avg       0.89      0.87      0.86       507\n",
      "\n",
      "out_of_domain_2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.98      0.70      0.82      5160\n",
      "      sexist       0.28      0.91      0.43       657\n",
      "\n",
      "    accuracy                           0.73      5817\n",
      "   macro avg       0.63      0.81      0.62      5817\n",
      "weighted avg       0.90      0.73      0.78      5817\n",
      "\n",
      "out_of_domain_3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.98      0.33      0.50     14088\n",
      "      sexist       0.33      0.98      0.50      4812\n",
      "\n",
      "    accuracy                           0.50     18900\n",
      "   macro avg       0.65      0.66      0.50     18900\n",
      "weighted avg       0.81      0.50      0.50     18900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for test_set in test_set_data['sexism']:\n",
    "    print(test_set)\n",
    "    print(classification_report(test_set_data_unavail['sexism'][test_set]['sexism'],\n",
    "                                test_set_data_unavail['sexism'][test_set]['chatgpt_label_aggregate']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "massive-absence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>text</th>\n",
       "      <th>sexism</th>\n",
       "      <th>chatgpt_labels</th>\n",
       "      <th>chatgpt_label_aggregate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5d654919ce2c6bd733477d59</td>\n",
       "      <td>Maybe the girls should have less tickets on th...</td>\n",
       "      <td>sexist</td>\n",
       "      <td>[Sexist., Sexist., Sexist.]</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5d654904ce2c6bd733475d0c</td>\n",
       "      <td>ABCDEFG means  A Boy Can Do  Everything For a ...</td>\n",
       "      <td>non-sexist</td>\n",
       "      <td>[Sexist. The sentence reinforces gender stereo...</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5d654914ce2c6bd7334772b3</td>\n",
       "      <td>Today in \"things GamerGate does to try to stop...</td>\n",
       "      <td>non-sexist</td>\n",
       "      <td>[Non-sexist., Non-sexist., non-sexist]</td>\n",
       "      <td>non-sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5d654901ce2c6bd733475c0e</td>\n",
       "      <td>Nothing like a man willing to spoil you. 😌 how...</td>\n",
       "      <td>non-sexist</td>\n",
       "      <td>[Sexist., Sexist., Sexist.]</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5ddc4fe8174b03a4c6aaf74b</td>\n",
       "      <td>Having a job means having a life of your own</td>\n",
       "      <td>non-sexist</td>\n",
       "      <td>[non-sexist, Non-sexist., non-sexist]</td>\n",
       "      <td>non-sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1219</th>\n",
       "      <td>5d654922ce2c6bd733479046</td>\n",
       "      <td>I find it strange there are females working on...</td>\n",
       "      <td>sexist</td>\n",
       "      <td>[Sexist., Sexist., Sexist.]</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220</th>\n",
       "      <td>5d654924ce2c6bd73347955f</td>\n",
       "      <td>this election I'm just voting for the candidat...</td>\n",
       "      <td>non-sexist</td>\n",
       "      <td>[Sexist., Sexist., Sexist.]</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1221</th>\n",
       "      <td>5d65490ece2c6bd733476bd8</td>\n",
       "      <td>Dont be disheartened emilie n sherri! #MKR</td>\n",
       "      <td>non-sexist</td>\n",
       "      <td>[Non-sexist., Non-sexist., Non-sexist.]</td>\n",
       "      <td>non-sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>5d65491ece2c6bd7334784aa</td>\n",
       "      <td>RT @eoind87 Great comment from a lad in class ...</td>\n",
       "      <td>sexist</td>\n",
       "      <td>[Sexist., Sexist., Sexist.]</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1223</th>\n",
       "      <td>5ddc4fe8174b03a4c6aaf603</td>\n",
       "      <td>Marriage is a partnership in which the wife an...</td>\n",
       "      <td>non-sexist</td>\n",
       "      <td>[Non-sexist., Non-sexist., non-sexist]</td>\n",
       "      <td>non-sexist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1224 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           _id  \\\n",
       "0     5d654919ce2c6bd733477d59   \n",
       "1     5d654904ce2c6bd733475d0c   \n",
       "2     5d654914ce2c6bd7334772b3   \n",
       "3     5d654901ce2c6bd733475c0e   \n",
       "4     5ddc4fe8174b03a4c6aaf74b   \n",
       "...                        ...   \n",
       "1219  5d654922ce2c6bd733479046   \n",
       "1220  5d654924ce2c6bd73347955f   \n",
       "1221  5d65490ece2c6bd733476bd8   \n",
       "1222  5d65491ece2c6bd7334784aa   \n",
       "1223  5ddc4fe8174b03a4c6aaf603   \n",
       "\n",
       "                                                   text      sexism  \\\n",
       "0     Maybe the girls should have less tickets on th...      sexist   \n",
       "1     ABCDEFG means  A Boy Can Do  Everything For a ...  non-sexist   \n",
       "2     Today in \"things GamerGate does to try to stop...  non-sexist   \n",
       "3     Nothing like a man willing to spoil you. 😌 how...  non-sexist   \n",
       "4          Having a job means having a life of your own  non-sexist   \n",
       "...                                                 ...         ...   \n",
       "1219  I find it strange there are females working on...      sexist   \n",
       "1220  this election I'm just voting for the candidat...  non-sexist   \n",
       "1221         Dont be disheartened emilie n sherri! #MKR  non-sexist   \n",
       "1222  RT @eoind87 Great comment from a lad in class ...      sexist   \n",
       "1223  Marriage is a partnership in which the wife an...  non-sexist   \n",
       "\n",
       "                                         chatgpt_labels  \\\n",
       "0                           [Sexist., Sexist., Sexist.]   \n",
       "1     [Sexist. The sentence reinforces gender stereo...   \n",
       "2                [Non-sexist., Non-sexist., non-sexist]   \n",
       "3                           [Sexist., Sexist., Sexist.]   \n",
       "4                 [non-sexist, Non-sexist., non-sexist]   \n",
       "...                                                 ...   \n",
       "1219                        [Sexist., Sexist., Sexist.]   \n",
       "1220                        [Sexist., Sexist., Sexist.]   \n",
       "1221            [Non-sexist., Non-sexist., Non-sexist.]   \n",
       "1222                        [Sexist., Sexist., Sexist.]   \n",
       "1223             [Non-sexist., Non-sexist., non-sexist]   \n",
       "\n",
       "     chatgpt_label_aggregate  \n",
       "0                     sexist  \n",
       "1                     sexist  \n",
       "2                 non-sexist  \n",
       "3                     sexist  \n",
       "4                 non-sexist  \n",
       "...                      ...  \n",
       "1219                  sexist  \n",
       "1220                  sexist  \n",
       "1221              non-sexist  \n",
       "1222                  sexist  \n",
       "1223              non-sexist  \n",
       "\n",
       "[1224 rows x 5 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_data['sexism']['in_domain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "faced-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sets = ['in_domain', 'out_of_domain', \n",
    "             'out_of_domain_2', 'out_of_domain_3', 'out_of_domain_4', \n",
    "             'hatecheck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "narrow-design",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_set_data = {}\n",
    "\n",
    "# for construct in ['hatespeech']:\n",
    "#     test_set_data[construct] = {}\n",
    "#     for test_set in test_sets:\n",
    "#         test_path = '../../../../socialCAD_/data/data/%s/test/%s.csv' %(construct, test_set)\n",
    "#         test_set_data[construct][test_set] = pd.read_csv(test_path, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "secondary-needle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## do once and save\n",
    "\n",
    "# for test_set in test_set_data['hatespeech']:\n",
    "#     results = []\n",
    "#     for _, row in test_set_data['hatespeech'][test_set].iterrows():\n",
    "#         result = []\n",
    "#         try:\n",
    "#             responses = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\", messages=[{\"role\": \"user\", \"content\": create_prompt_label_hatespeech(row['text'])}],n=3)\n",
    "#         except:\n",
    "#             time.sleep(60)\n",
    "#             responses = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\", messages=[{\"role\": \"user\", \"content\": create_prompt_label_hatespeech(row['text'])}],n=3)\n",
    "#         for response in responses['choices']:\n",
    "#             result.append(response['message']['content'])\n",
    "#         results.append(result)\n",
    "#     test_set_data['hatespeech'][test_set]['chatgpt_labels'] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "exposed-shepherd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../../designed_data/hatespeech_chatgpt_labels.pickle', 'wb') as handle:\n",
    "#     pickle.dump(test_set_data['hatespeech'], handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('../../designed_data/hatespeech_chatgpt_labels.pickle', 'rb') as handle:\n",
    "    test_set_data['hatespeech'] = pickle.load(handle)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "distributed-performer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hatespeech\n",
       "hate         5256\n",
       "not hate    17067\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_data['hatespeech'][test_set].groupby('hatespeech').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "continuing-iceland",
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_set in test_set_data['hatespeech']:\n",
    "    test_set_data_unavail['hatespeech'][test_set] = test_set_data['hatespeech'][test_set].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fifty-wellington",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_no_label = {}\n",
    "for test_set in  test_set_data['hatespeech']:\n",
    "    count_no_label[test_set] = 0\n",
    "    results = []\n",
    "    results_un = []\n",
    "    for _, row in test_set_data['hatespeech'][test_set].iterrows():\n",
    "        label = row['chatgpt_labels'][0].lower().translate(str.maketrans('', '', string.punctuation))\n",
    "        label = label.split(' ')[0]\n",
    "        label_un = label\n",
    "        if label == 'not':\n",
    "            label = 'not hate'\n",
    "            label_un = 'not hate'\n",
    "        \n",
    "        if label != 'hate' and label != 'not hate':\n",
    "            label = 'not hate'\n",
    "            label_un = 'unavailable'\n",
    "            count_no_label[test_set] += 1\n",
    "\n",
    "        results.append(label)\n",
    "        results_un.append(label_un)\n",
    "    test_set_data['hatespeech'][test_set]['chatgpt_label_aggregate'] = results\n",
    "    test_set_data_unavail['hatespeech'][test_set]['chatgpt_label_aggregate'] = results_un\n",
    "    #[test_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "experimental-dependence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('in_domain', 0.12620320855614972),\n",
       " ('out_of_domain', 0.5188003315963998),\n",
       " ('out_of_domain_2', 0.076),\n",
       " ('out_of_domain_3', 0.34220310890113337),\n",
       " ('out_of_domain_4', 0.06581013561741614),\n",
       " ('hatecheck', 0.05472103004291846)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(i, count_no_label[i]/len(test_set_data['hatespeech'][i])) for i in count_no_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "attractive-contents",
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_set in test_set_data['hatespeech'].keys():\n",
    "    test_set_data_unavail['hatespeech'][test_set] = test_set_data_unavail['hatespeech'][test_set][test_set_data_unavail['hatespeech'][test_set]['chatgpt_label_aggregate'] \\\n",
    "                                                                                                  != 'unavailable'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "global-brick",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_domain\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        hate       0.70      0.83      0.76       427\n",
      "    not hate       0.77      0.62      0.68       390\n",
      "\n",
      "    accuracy                           0.73       817\n",
      "   macro avg       0.73      0.72      0.72       817\n",
      "weighted avg       0.73      0.73      0.72       817\n",
      "\n",
      "out_of_domain\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        hate       0.64      0.89      0.75      5069\n",
      "    not hate       0.94      0.78      0.85     11184\n",
      "\n",
      "    accuracy                           0.81     16253\n",
      "   macro avg       0.79      0.83      0.80     16253\n",
      "weighted avg       0.85      0.81      0.82     16253\n",
      "\n",
      "out_of_domain_2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        hate       0.61      0.86      0.71      1187\n",
      "    not hate       0.85      0.58      0.69      1585\n",
      "\n",
      "    accuracy                           0.70      2772\n",
      "   macro avg       0.73      0.72      0.70      2772\n",
      "weighted avg       0.75      0.70      0.70      2772\n",
      "\n",
      "out_of_domain_3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        hate       0.53      0.69      0.60      3015\n",
      "    not hate       0.91      0.84      0.88     11669\n",
      "\n",
      "    accuracy                           0.81     14684\n",
      "   macro avg       0.72      0.77      0.74     14684\n",
      "weighted avg       0.83      0.81      0.82     14684\n",
      "\n",
      "out_of_domain_4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        hate       0.20      0.27      0.23      1157\n",
      "    not hate       0.83      0.77      0.80      5387\n",
      "\n",
      "    accuracy                           0.68      6544\n",
      "   macro avg       0.52      0.52      0.52      6544\n",
      "weighted avg       0.72      0.68      0.70      6544\n",
      "\n",
      "hatecheck\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        hate       0.88      1.00      0.94      2553\n",
      "    not hate       0.98      0.65      0.78       971\n",
      "\n",
      "    accuracy                           0.90      3524\n",
      "   macro avg       0.93      0.82      0.86      3524\n",
      "weighted avg       0.91      0.90      0.89      3524\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for test_set in test_set_data_unavail['hatespeech']:\n",
    "    print(test_set)\n",
    "    print(classification_report(test_set_data_unavail['hatespeech'][test_set]['hatespeech'],\n",
    "                                test_set_data_unavail['hatespeech'][test_set]['chatgpt_label_aggregate']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "quantitative-senate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_domain\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        hate       0.70      0.75      0.73       471\n",
      "    not hate       0.73      0.68      0.70       464\n",
      "\n",
      "    accuracy                           0.71       935\n",
      "   macro avg       0.72      0.71      0.71       935\n",
      "weighted avg       0.72      0.71      0.71       935\n",
      "\n",
      "out_of_domain\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        hate       0.64      0.31      0.42     14614\n",
      "    not hate       0.62      0.87      0.73     19162\n",
      "\n",
      "    accuracy                           0.63     33776\n",
      "   macro avg       0.63      0.59      0.57     33776\n",
      "weighted avg       0.63      0.63      0.59     33776\n",
      "\n",
      "out_of_domain_2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        hate       0.61      0.81      0.70      1260\n",
      "    not hate       0.82      0.62      0.71      1740\n",
      "\n",
      "    accuracy                           0.70      3000\n",
      "   macro avg       0.71      0.72      0.70      3000\n",
      "weighted avg       0.73      0.70      0.70      3000\n",
      "\n",
      "out_of_domain_3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        hate       0.53      0.40      0.45      5256\n",
      "    not hate       0.83      0.89      0.86     17067\n",
      "\n",
      "    accuracy                           0.77     22323\n",
      "   macro avg       0.68      0.64      0.66     22323\n",
      "weighted avg       0.76      0.77      0.76     22323\n",
      "\n",
      "out_of_domain_4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        hate       0.20      0.25      0.22      1267\n",
      "    not hate       0.83      0.78      0.80      5738\n",
      "\n",
      "    accuracy                           0.69      7005\n",
      "   macro avg       0.51      0.52      0.51      7005\n",
      "weighted avg       0.71      0.69      0.70      7005\n",
      "\n",
      "hatecheck\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        hate       0.88      0.99      0.93      2563\n",
      "    not hate       0.98      0.71      0.82      1165\n",
      "\n",
      "    accuracy                           0.90      3728\n",
      "   macro avg       0.93      0.85      0.88      3728\n",
      "weighted avg       0.91      0.90      0.90      3728\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for test_set in test_set_data['hatespeech']:\n",
    "    print(test_set)\n",
    "    print(classification_report(test_set_data['hatespeech'][test_set]['hatespeech'],\n",
    "                                test_set_data['hatespeech'][test_set]['chatgpt_label_aggregate']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "efficient-adobe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../../designed_data/hatespeech_chatgpt_labels.pickle', 'wb') as handle:\n",
    "#     pickle.dump(test_set_data['hatespeech'], handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
